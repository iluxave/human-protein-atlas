{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUInceptionV3_RNN_TF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "najlB4tnapzz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install imgaug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h4wTFMNrAZY6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/competitions/human-protein-atlas-image-classification/output\n",
        "import os\n",
        "os.chdir('/content/competitions/human-protein-atlas-image-classification')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RVBQEkhE1wFO",
        "colab_type": "code",
        "outputId": "c27fe1e7-6c3a-408b-c5fc-9ecae41b8da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.85.239.50:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 10946900395850354813),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2150489995054598000),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 2841688867380542543),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12311736082261458102),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16530568811090666039),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6106581041025008983),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12334059195984386793),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17934693137254689662),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 12496630498973520767),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6559484486240104935),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2283344607825868653),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 13911280868096962566)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a5OO_GRS5PdZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.io\n",
        "from skimage.transform import resize\n",
        "#from imgaug import augmenters as iaa\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.utils import class_weight, shuffle\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "SIZE = 299\n",
        "SEED = 777\n",
        "THRESHOLD = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TopFylv55Pde",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UAu2PQ_PD_fX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GCS access helpers ##\n",
        "Courtesy of https://stackoverflow.com/a/52106361/7724174\n",
        "\n",
        "These functions let us get data from GCS into our notebook."
      ]
    },
    {
      "metadata": {
        "id": "bDZlL-_K5Pdg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Load dataset info\n",
        "#DIR = '../input/'\n",
        "#DIR='gs://human-protein-atlas-kaggle/'\n",
        "#data = dd.read_csv(DIR+'train.csv')\n",
        "#data = data.compute()\n",
        "\n",
        "DATA_DIR='gs://human-protein-atlas-kaggle/'\n",
        "\n",
        "from tensorflow.python.lib.io import file_io\n",
        "with file_io.FileIO(DATA_DIR+'train.csv', 'r') as f:\n",
        "    data = pd.read_csv(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KRMpE3B95Pdr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SHAPE = (299, 299, 3)\n",
        "NUM_CLASSES=28\n",
        "epochs = 100;\n",
        "#epochs = 30\n",
        "#batch_size = 256;\n",
        "VAL_RATIO = .1;\n",
        "DEBUG = False\n",
        "channels = [\"green\", \"blue\", \"red\"]\n",
        "lstmUnits=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ciXtnu0dfPO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data input pipline ##\n",
        "This isn't fully optimized yet, but it's good enough."
      ]
    },
    {
      "metadata": {
        "id": "kAm-HbRHN-U3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TF_DIR=DATA_DIR+'train'\n",
        "DS_DIMS=[512,512]\n",
        "NN_DIMS=[299,299]\n",
        "REC_BUF_SIZE=453762 # This is approximate size for 512x512 images\n",
        "NUM_PARALLEL_CALLS=8 # number of cores in the system\n",
        "class HPADataset:\n",
        "    def __init__(self, shards, aug=True):\n",
        "        self.shards = shards\n",
        "        self.aug = aug\n",
        "    def input_fn(self, params):\n",
        "        batch_size=params['batch_size']\n",
        "        def _parse_function(example_proto):\n",
        "            features = {}\n",
        "            for c in channels:\n",
        "                features[\"image/%s/filename\"%c] = tf.FixedLenFeature((), tf.string, default_value=\"\")\n",
        "                features[\"image/%s/encoded\"%c] = tf.FixedLenFeature((), tf.string, default_value=\"\")\n",
        "            features[\"image/label\"] = tf.FixedLenFeature((NUM_CLASSES), tf.float32, default_value=[0]*NUM_CLASSES)\n",
        "            parsed_features = tf.parse_single_example(example_proto, features)\n",
        "            imgs=[]\n",
        "            for c in channels:\n",
        "                img=parsed_features['image/%s/encoded'%c]\n",
        "                #print(img)\n",
        "                img=tf.image.decode_png(img, channels=1)\n",
        "                shape=tf.shape(img)\n",
        "                #shape_print=tf.print(shape)\n",
        "                img=tf.reshape(img, DS_DIMS)\n",
        "                imgs.append(img)\n",
        "            image=tf.stack(imgs, axis=-1, name='combine_channels')\n",
        "            image=tf.image.resize_images(image, NN_DIMS)\n",
        "            # For simplicity, we'll use imgaug with py_op here\n",
        "            def augment(image):\n",
        "                augment_img = iaa.Sequential([\n",
        "                    iaa.OneOf([\n",
        "                        iaa.Affine(rotate=0),\n",
        "                        iaa.Affine(rotate=90),\n",
        "                        iaa.Affine(rotate=180),\n",
        "                        iaa.Affine(rotate=270),\n",
        "                        iaa.Fliplr(0.5),\n",
        "                        iaa.Flipud(0.5),\n",
        "                    ])], random_order=True)\n",
        "\n",
        "                image_aug = augment_img.augment_image(image)\n",
        "                return image_aug\n",
        "            if self.aug:\n",
        "                image=tf.py_func(augment, [image], tf.float32, name='augment')\n",
        "                image=tf.reshape(image, NN_DIMS+[len(channels)])\n",
        "            image=tf.cast(image, tf.float32)\n",
        "            image=image / 255.\n",
        "            return image, parsed_features[\"image/label\"]\n",
        "        fnames=['{dir}/hpa_{w}x{h}_{num}.tfrecords'.format(dir=TF_DIR, w=DS_DIMS[0], h=DS_DIMS[1], num=shard) for shard in self.shards]\n",
        "        dataset=tf.data.TFRecordDataset(fnames,\n",
        "                                        buffer_size=REC_BUF_SIZE*2*len(self.shards),\n",
        "                                        num_parallel_reads=len(self.shards))\n",
        "        dataset=dataset.map(_parse_function, num_parallel_calls=NUM_PARALLEL_CALLS)\n",
        "        dataset=dataset.shuffle(1000)\n",
        "        dataset=dataset.prefetch(batch_size*8)\n",
        "        dataset=dataset.batch(batch_size, drop_remainder=True)\n",
        "        dataset=dataset.prefetch(2)\n",
        "        if params['mode']!='predict':\n",
        "            dataset=dataset.repeat()\n",
        "            return dataset.make_one_shot_iterator().get_next()\n",
        "        return dataset\n",
        "#with tf.Graph().as_default():\n",
        "#    test=HPADataset([1,2]).input_fn()\n",
        "#    with tf.Session() as sess:\n",
        "#        sess.run(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9qX02e8aPkb3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_VNMbwOsvV-4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tg = HPADataset(range(8), False)\n",
        "vg = HPADataset([8, 9], False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JoxbV4Hsd1jA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model ##\n",
        "\n",
        "What follows is our model based on pure tensorflow and the inception model present there. Large portions of this code are lifted from https://github.com/tensorflow/tpu/blob/master/models/experimental/inception/inception_v3.py\n"
      ]
    },
    {
      "metadata": {
        "id": "kD7NGt2Y5Pdz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.contrib import summary\n",
        "from tensorflow.contrib.framework.python.ops import arg_scope\n",
        "from tensorflow.contrib.slim.nets import inception\n",
        "from tensorflow.contrib.training.python.training import evaluation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k3QEuM7qf4rp",
        "colab_type": "code",
        "outputId": "648e4869-d6f1-4ec9-db9c-1935611bd7d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "### Some model settings\n",
        "precision='float32'\n",
        "log_device_placement=False\n",
        "clear_update_collections=True\n",
        "num_classes=NUM_CLASSES\n",
        "display_tensors=True\n",
        "use_tpu=True\n",
        "train_batch_size=128\n",
        "geval_batch_size=128\n",
        "glearning_rate=0.165\n",
        "learning_rate_decay=0.94\n",
        "use_learning_rate_warmup=False\n",
        "warmup_epochs=7\n",
        "cold_epochs=2\n",
        "learning_rate_decay_epochs=6\n",
        "skip_host_call=True\n",
        "goptimizer='Adam'\n",
        "moving_average=True\n",
        "MOVING_AVERAGE_DECAY = 0.995\n",
        "# Batchnorm moving mean/variance parameters\n",
        "BATCH_NORM_DECAY = 0.996\n",
        "BATCH_NORM_EPSILON = 1e-3\n",
        "\n",
        "WEIGHT_DECAY = 0.00004\n",
        "RMSPROP_DECAY = 0.9                # Decay term for RMSProp.\n",
        "RMSPROP_MOMENTUM = 0.9             # Momentum in RMSProp.\n",
        "RMSPROP_EPSILON = 1.0              # Epsilon term for RMSProp.\n",
        "\n",
        "min_depth=16\n",
        "transpose_enabled=False\n",
        "spatial_squeeze=True\n",
        "\n",
        "_NUM_TRAIN_IMAGES = 24858\n",
        "_NUM_EVAL_IMAGES = 6214\n",
        "ITERATIONS=_NUM_TRAIN_IMAGES*epochs/train_batch_size\n",
        "num_shards=8 # 8 in original..\n",
        "#model_dir='/content/competitions/human-protein-atlas-image-classification/output'\n",
        "model_dir=DATA_DIR+'output-noaux/'\n",
        "save_checkpoints_secs=1000\n",
        "save_summary_steps=100\n",
        "eval_timeout=None\n",
        "train_steps_per_eval=int(_NUM_TRAIN_IMAGES/train_batch_size) # essentially one epoch\n",
        "\n",
        "dropout_keep_prob=0.8\n",
        "train_steps=int(ITERATIONS)\n",
        "print('Will train for {train} steps'.format(train=train_steps))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Will train for 19420 steps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9NYAVMEH45rM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def tensor_transform_fn(data, perm):\n",
        "  \"\"\"Transpose function.\n",
        "\n",
        "  This function is used to transpose an image tensor on the host and then\n",
        "  perform an inverse transpose on the TPU. The transpose on the TPU gets\n",
        "  effectively elided thus voiding any associated computational cost.\n",
        "\n",
        "  NOTE: Eventually the compiler will be able to detect when this kind of\n",
        "  operation may prove beneficial and perform these types of transformations\n",
        "  implicitly, voiding the need for user intervention\n",
        "\n",
        "  Args:\n",
        "    data: Tensor to be transposed\n",
        "    perm: New ordering of dimensions\n",
        "\n",
        "  Returns:\n",
        "    Transposed tensor\n",
        "  \"\"\"\n",
        "  if transpose_enabled:\n",
        "    return tf.transpose(data, perm)\n",
        "  return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Up9dhjFpe-14",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib import layers\n",
        "from tensorflow.contrib.layers.python.layers import layers as layers_lib\n",
        "from tensorflow.python.ops import array_ops\n",
        "\n",
        "def inception_model_fn(features, labels, mode, params):\n",
        "    \"\"\"Inception v3 model using Estimator API.\"\"\"\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    is_eval = (mode == tf.estimator.ModeKeys.EVAL)\n",
        "\n",
        "    if isinstance(features, dict):\n",
        "        features = features['feature']\n",
        "\n",
        "    features = tensor_transform_fn(features, params['input_perm'])\n",
        "\n",
        "    # This nested function allows us to avoid duplicating the logic which\n",
        "    # builds the network, for different values of --precision.\n",
        "    def build_inception_v3(final_endpoint='Mixed_7c', scope=None):\n",
        "        with tf.variable_scope(\n",
        "            scope, 'InceptionV3', [features, num_classes], reuse=None) as scope:\n",
        "            with arg_scope(\n",
        "              [layers_lib.batch_norm, layers_lib.dropout], is_training=is_training):\n",
        "              net, end_points = inception.inception_v3_base(\n",
        "                  features,\n",
        "                  final_endpoint=final_endpoint\n",
        "              )\n",
        "\n",
        "              # Build our RNNs\n",
        "              def build_rnn(endpoint):\n",
        "                # 1. Unroll our logits horisonatlly and vertically\n",
        "                #print(\"Input endpoint\", endpoint)\n",
        "                shape=endpoint.shape.as_list()\n",
        "                if shape[0] is None:\n",
        "                    bd=-1\n",
        "                else:\n",
        "                    bd=shape[0]\n",
        "                shape=(bd, shape[1]*shape[2], shape[3])\n",
        "                input_width=tf.reshape(endpoint, shape)\n",
        "                input_height=tf.transpose(endpoint, (0, 2, 1, 3))\n",
        "                input_height=tf.reshape(input_height, shape)\n",
        "                lstmCellW = tf.contrib.rnn.LSTMCell(num_units=lstmUnits, use_peepholes=True)\n",
        "                lstmCellH = tf.contrib.rnn.LSTMCell(num_units=lstmUnits, use_peepholes=True)\n",
        "                wouts, wstate=tf.nn.dynamic_rnn(lstmCellW, input_width, scope='width', dtype=tf.float32, parallel_iterations=1024)\n",
        "                houts, hstate=tf.nn.dynamic_rnn(lstmCellH, input_height, scope='height', dtype=tf.float32, parallel_iterations=1024)\n",
        "                logits=tf.concat([wstate.h, hstate.h], name='Logits', axis=-1)\n",
        "                return logits\n",
        "              rnn_logits=[]\n",
        "              attachements=['Mixed_7b', 'Mixed_7a', 'Mixed_6e']\n",
        "              #attachements=['Mixed_7a']\n",
        "              for att_pt in attachements:\n",
        "                    with tf.variable_scope(att_pt+'_rnn'):\n",
        "                        rnn_logits.append(build_rnn(end_points[att_pt]))\n",
        "              rnn_logits=tf.concat(rnn_logits, name='FinalRNNLogits', axis=-1)\n",
        "\n",
        "              depth = lambda d: max(d, min_depth)\n",
        "              if 'Mixed_6e' in end_points and False:\n",
        "                  # Auxiliary Head logits\n",
        "                  with arg_scope(\n",
        "                      [layers.conv2d, layers_lib.max_pool2d, layers_lib.avg_pool2d],\n",
        "                      stride=1,\n",
        "                      padding='SAME'):\n",
        "                    aux_logits = end_points['Mixed_6e']\n",
        "                    with tf.variable_scope('AuxLogits'):\n",
        "                      aux_logits = layers_lib.avg_pool2d(\n",
        "                          aux_logits, [5, 5],\n",
        "                          stride=3,\n",
        "                          padding='VALID',\n",
        "                          scope='AvgPool_1a_5x5')\n",
        "                      aux_logits = layers.conv2d(\n",
        "                          aux_logits, depth(128), [1, 1], scope='Conv2d_1b_1x1')\n",
        "\n",
        "                      # Shape of feature map before the final layer.\n",
        "                      kernel_size = [5, 5]\n",
        "                      aux_logits = layers.conv2d(\n",
        "                          aux_logits,\n",
        "                          depth(768),\n",
        "                          kernel_size,\n",
        "                          weights_initializer=tf.initializers.truncated_normal(stddev=0.01),\n",
        "                          padding='VALID',\n",
        "                          scope='Conv2d_2a_{}x{}'.format(*kernel_size))\n",
        "                      aux_logits = layers.conv2d(\n",
        "                          aux_logits,\n",
        "                          num_classes, [1, 1],\n",
        "                          activation_fn=None,\n",
        "                          normalizer_fn=None,\n",
        "                          weights_initializer=tf.initializers.truncated_normal(stddev=0.001),\n",
        "                          scope='Conv2d_2b_1x1')\n",
        "                      if spatial_squeeze:\n",
        "                        aux_logits = array_ops.squeeze(\n",
        "                            aux_logits, name='SpatialSqueeze')\n",
        "                      end_points['AuxLogits'] = aux_logits\n",
        "            # Final pooling and prediction\n",
        "            with tf.variable_scope('Logits'):\n",
        "                #kernel_size = [8,8]\n",
        "                #net = layers_lib.avg_pool2d(net, kernel_size, padding='VALID', scope='AvgPool_1a{}x{}'.format(*kernel_size))\n",
        "                ## 1x1x2048\n",
        "                #net = layers_lib.dropout(net, keep_prob=dropout_keep_prob, scope='Dropout_1b')\n",
        "                #end_points['PreLogits']=net\n",
        "                ##2048\n",
        "                #logits = layers.conv2d(net, num_classes, [1,1], activation_fn=None, normalizer_fn=None, scope='Conv2d_1c_1x1')\n",
        "                #if spatial_squeeze:\n",
        "                #    logits = array_ops.squeeze(logits, [1,2], name='SpatialSqueeze')\n",
        "                #end_points['Logits']=logits\n",
        "                #end_points['Predictions']=tf.nn.sigmoid(logits, name='Predicitons')\n",
        "                #return logits, end_points\n",
        "\n",
        "                net = rnn_logits\n",
        "                end_points['PreLogits']=net\n",
        "                end_points['rnn_logits']=net\n",
        "                net = layers_lib.dropout(net, keep_prob=dropout_keep_prob, scope='Dropout_1b')\n",
        "                print(net)\n",
        "                net = tf.expand_dims(net, 1)\n",
        "                net = tf.expand_dims(net, 1)\n",
        "                print(net)\n",
        "                logits = layers.conv2d(net, num_classes, 1, activation_fn=None, normalizer_fn=None, scope='Conv2d_1c_1x1')\n",
        "                if spatial_squeeze:\n",
        "                    logits = array_ops.squeeze(logits, [1,2], name='SpatialSqueeze')\n",
        "                # 28\n",
        "                end_points['Logits']=logits\n",
        "                end_points['Predictions'] = tf.nn.sigmoid(logits, name='Predictions')\n",
        "                return logits, end_points\n",
        "\n",
        "    def build_network(precision):\n",
        "        if precision == 'bfloat16':\n",
        "            with tf.contrib.tpu.bfloat16_scope():\n",
        "                logits, end_points = build_inception_v3()\n",
        "            logits = tf.cast(logits, tf.float32)\n",
        "        elif precision == 'float32':\n",
        "            logits, end_points = build_inception_v3()\n",
        "        return logits, end_points\n",
        "\n",
        "    if clear_update_collections:\n",
        "        # updates_collections must be set to None in order to use fused batchnorm\n",
        "        with arg_scope(inception.inception_v3_arg_scope(\n",
        "            weight_decay=0.0,\n",
        "            batch_norm_decay=BATCH_NORM_DECAY,\n",
        "            batch_norm_epsilon=BATCH_NORM_EPSILON,\n",
        "            updates_collections=None)):\n",
        "            logits, end_points = build_network('float32')\n",
        "    else:\n",
        "        with arg_scope(inception.inception_v3_arg_scope(\n",
        "            batch_norm_decay=BATCH_NORM_DECAY,\n",
        "            batch_norm_epsilon=BATCH_NORM_EPSILON)):\n",
        "            logits, end_points = build_network('float32')\n",
        "\n",
        "    predictions = {\n",
        "        'logits': logits,\n",
        "        'classes': tf.math.greater(logits, 0.2),\n",
        "        'probabilities': end_points['Predictions'],\n",
        "        #'rnn_logits': end_points['rnn_logits'],\n",
        "        #'dropout': end_points['dropout'],\n",
        "        'prelogits': end_points['PreLogits'],\n",
        "        'labels': labels,\n",
        "    }\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return  tf.contrib.tpu.TPUEstimatorSpec(\n",
        "            mode=mode,\n",
        "            predictions=predictions,\n",
        "            export_outputs={\n",
        "                'classify': tf.estimator.export.PredictOutput(predictions)\n",
        "            })\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.EVAL and display_tensors and (\n",
        "        not use_tpu):\n",
        "        with tf.control_dependencies([\n",
        "            tf.Print(\n",
        "                predictions['classes'], [predictions['classes']],\n",
        "                summarize=geval_batch_size,\n",
        "                message='prediction: ')\n",
        "        ]):\n",
        "            labels = tf.Print(\n",
        "                labels, [labels], summarize=geval_batch_size, message='label: ')\n",
        "\n",
        "    # in our case labels come pre-encoded\n",
        "    one_hot_labels = labels #tf.one_hot(labels, num_classes, dtype=tf.int32)\n",
        "\n",
        "    if 'AuxLogits' in end_points:\n",
        "        tf.losses.sigmoid_cross_entropy(\n",
        "            multi_class_labels=one_hot_labels,\n",
        "            logits=tf.cast(end_points['AuxLogits'], tf.float32),\n",
        "            weights=0.4,\n",
        "            label_smoothing=0.1,\n",
        "            scope='aux_loss')\n",
        "\n",
        "    tf.losses.sigmoid_cross_entropy(\n",
        "        multi_class_labels=one_hot_labels,\n",
        "        logits=logits,\n",
        "        #weights=1.0,\n",
        "        #label_smoothing=0.1,\n",
        "        reduction=tf.losses.Reduction.MEAN\n",
        "    )\n",
        "\n",
        "    losses = tf.add_n(tf.losses.get_losses())\n",
        "    l2_loss = []\n",
        "    for v in tf.trainable_variables():\n",
        "        if 'BatchNorm' not in v.name and 'weights' in v.name:\n",
        "            l2_loss.append(tf.nn.l2_loss(v))\n",
        "    loss = losses + WEIGHT_DECAY * tf.add_n(l2_loss)\n",
        "\n",
        "    initial_learning_rate = glearning_rate * train_batch_size / 256\n",
        "    if use_learning_rate_warmup:\n",
        "        # Adjust initial learning rate to match final warmup rate\n",
        "        warmup_decay = learning_rate_decay**(\n",
        "            (warmup_epochs + cold_epochs) /\n",
        "            learning_rate_decay_epochs)\n",
        "        adj_initial_learning_rate = initial_learning_rate * warmup_decay\n",
        "\n",
        "    final_learning_rate = 0.0001 * initial_learning_rate\n",
        "\n",
        "    host_call = None\n",
        "    train_op = None\n",
        "  \n",
        "    if is_training:\n",
        "        batches_per_epoch = _NUM_TRAIN_IMAGES / train_batch_size\n",
        "        global_step = tf.train.get_or_create_global_step()\n",
        "        current_epoch = tf.cast(\n",
        "            (tf.cast(global_step, tf.float32) / batches_per_epoch), tf.int32)\n",
        "\n",
        "        learning_rate = tf.train.exponential_decay(\n",
        "            learning_rate=initial_learning_rate,\n",
        "            global_step=global_step,\n",
        "            decay_steps=int(learning_rate_decay_epochs * batches_per_epoch),\n",
        "            decay_rate=learning_rate_decay,\n",
        "            staircase=True)\n",
        "\n",
        "        if use_learning_rate_warmup:\n",
        "            wlr = 0.1 * adj_initial_learning_rate\n",
        "            wlr_height = tf.cast(\n",
        "                0.9 * adj_initial_learning_rate /\n",
        "                (warmup_epochs + learning_rate_decay_epochs - 1),\n",
        "                tf.float32)\n",
        "            epoch_offset = tf.cast(cold_epochs - 1, tf.int32)\n",
        "            exp_decay_start = (warmup_epochs + cold_epochs +\n",
        "                             learning_rate_decay_epochs)\n",
        "            lin_inc_lr = tf.add(\n",
        "                wlr, tf.multiply(\n",
        "                    tf.cast(tf.subtract(current_epoch, epoch_offset), tf.float32),\n",
        "                    wlr_height))\n",
        "            learning_rate = tf.where(\n",
        "                tf.greater_equal(current_epoch, cold_epochs),\n",
        "                (tf.where(tf.greater_equal(current_epoch, exp_decay_start),\n",
        "                          learning_rate, lin_inc_lr)),\n",
        "                wlr)\n",
        "\n",
        "        # Set a minimum boundary for the learning rate.\n",
        "        learning_rate = tf.maximum(\n",
        "            learning_rate, final_learning_rate, name='learning_rate')\n",
        "\n",
        "        if goptimizer == 'sgd':\n",
        "            tf.logging.info('Using SGD optimizer')\n",
        "            optimizer = tf.train.GradientDescentOptimizer(\n",
        "                learning_rate=learning_rate)\n",
        "        elif goptimizer == 'momentum':\n",
        "            tf.logging.info('Using Momentum optimizer')\n",
        "            optimizer = tf.train.MomentumOptimizer(\n",
        "                learning_rate=learning_rate, momentum=0.9)\n",
        "        elif goptimizer == 'RMS':\n",
        "            tf.logging.info('Using RMS optimizer')\n",
        "            optimizer = tf.train.RMSPropOptimizer(\n",
        "                learning_rate,\n",
        "                RMSPROP_DECAY,\n",
        "                momentum=RMSPROP_MOMENTUM,\n",
        "                epsilon=RMSPROP_EPSILON)\n",
        "        elif goptimizer == 'Adam':\n",
        "            tf.logging.info('Using Adam optimizer')\n",
        "            optimizer = tf.train.AdamOptimizer(\n",
        "                learning_rate,\n",
        "            )\n",
        "        else:\n",
        "            tf.logging.fatal('Unknown optimizer:', optimizer)\n",
        "\n",
        "        if use_tpu:\n",
        "            optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
        "\n",
        "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "        if params['warmup']:\n",
        "            trainable_vars = tf.contrib.framework.get_model_variables()\n",
        "            var_list=tf.contrib.framework.filter_variables(trainable_vars, exclude_patterns='.*Mixed_.*_rnn.*')\n",
        "            trainable_vars = tf.contrib.framework.get_trainable_variables()\n",
        "            var_list=tf.contrib.framework.filter_variables(trainable_vars, exclude_patterns=var_list)\n",
        "            print('Training', var_list)\n",
        "        else:\n",
        "            var_list=None\n",
        "        with tf.control_dependencies(update_ops):\n",
        "            train_op = optimizer.minimize(loss, global_step=global_step, var_list=var_list)\n",
        "        if moving_average:\n",
        "            ema = tf.train.ExponentialMovingAverage(\n",
        "                decay=MOVING_AVERAGE_DECAY, num_updates=global_step)\n",
        "            variables_to_average = (\n",
        "                tf.trainable_variables() + tf.moving_average_variables())\n",
        "            with tf.control_dependencies([train_op]), tf.name_scope('moving_average'):\n",
        "                train_op = ema.apply(variables_to_average)\n",
        "\n",
        "        # To log the loss, current learning rate, and epoch for Tensorboard, the\n",
        "        # summary op needs to be run on the host CPU via host_call. host_call\n",
        "        # expects [batch_size, ...] Tensors, thus reshape to introduce a batch\n",
        "        # dimension. These Tensors are implicitly concatenated to\n",
        "        # [params['batch_size']].\n",
        "        gs_t = tf.reshape(global_step, [1])\n",
        "        loss_t = tf.reshape(loss, [1])\n",
        "        lr_t = tf.reshape(learning_rate, [1])\n",
        "        ce_t = tf.reshape(current_epoch, [1])\n",
        "\n",
        "        if not skip_host_call:\n",
        "            def host_call_fn(gs, loss, lr, ce):\n",
        "                \"\"\"Training host call. Creates scalar summaries for training metrics.\n",
        "                This function is executed on the CPU and should not directly reference\n",
        "                any Tensors in the rest of the `model_fn`. To pass Tensors from the\n",
        "                model to the `metric_fn`, provide them as part of the `host_call`. See\n",
        "                https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/TPUEstimatorSpec\n",
        "                for more information.\n",
        "                Arguments should match the list of `Tensor` objects passed as the second\n",
        "                element in the tuple passed to `host_call`.\n",
        "                Args:\n",
        "                  gs: `Tensor with shape `[batch]` for the global_step\n",
        "                  loss: `Tensor` with shape `[batch]` for the training loss.\n",
        "                  lr: `Tensor` with shape `[batch]` for the learning_rate.\n",
        "                  ce: `Tensor` with shape `[batch]` for the current_epoch.\n",
        "                Returns:\n",
        "                  List of summary ops to run on the CPU host.\n",
        "                \"\"\"\n",
        "                gs = gs[0]\n",
        "                with summary.create_file_writer(model_dir).as_default():\n",
        "                    with summary.always_record_summaries():\n",
        "                        summary.scalar('loss', tf.reduce_mean(loss), step=gs)\n",
        "                        summary.scalar('learning_rate', tf.reduce_mean(lr), step=gs)\n",
        "                        summary.scalar('current_epoch', tf.reduce_mean(ce), step=gs)\n",
        "\n",
        "                    return summary.all_summary_ops()\n",
        "\n",
        "            host_call = (host_call_fn, [gs_t, loss_t, lr_t, ce_t])\n",
        "\n",
        "    eval_metrics = None\n",
        "    if is_eval:\n",
        "        def metric_fn(labels, logits):\n",
        "            \"\"\"Evaluation metric function. Evaluates accuracy.\n",
        "            This function is executed on the CPU and should not directly reference\n",
        "            any Tensors in the rest of the `model_fn`. To pass Tensors from the model\n",
        "            to the `metric_fn`, provide as part of the `eval_metrics`. See\n",
        "            https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/TPUEstimatorSpec\n",
        "            for more information.\n",
        "            Arguments should match the list of `Tensor` objects passed as the second\n",
        "            element in the tuple passed to `eval_metrics`.\n",
        "            Args:\n",
        "            labels: `Tensor` with shape `[batch, ]`.\n",
        "            logits: `Tensor` with shape `[batch, num_classes]`.\n",
        "            Returns:\n",
        "            A dict of the metrics to return from evaluation.\n",
        "            \"\"\"\n",
        "            probs=tf.nn.sigmoid(logits)\n",
        "            predictions = tf.math.greater(probs, 0.2)\n",
        "            recall = tf.metrics.recall(labels, predictions)\n",
        "            precision=tf.metrics.precision(labels, predictions)\n",
        "            f1=tf.contrib.metrics.f1_score(labels, probs)\n",
        "\n",
        "            return {\n",
        "              'recall': recall,\n",
        "              'precision': precision,\n",
        "              'f1': f1\n",
        "            }\n",
        "\n",
        "        eval_metrics = (metric_fn, [labels, logits])\n",
        "\n",
        "    return tf.contrib.tpu.TPUEstimatorSpec(\n",
        "        mode=mode,\n",
        "        loss=loss,\n",
        "        train_op=train_op,\n",
        "        host_call=host_call,\n",
        "        eval_metrics=eval_metrics)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4fSZX5_Tv44y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LoadEMAHook(tf.train.SessionRunHook):\n",
        "  \"\"\"Hook to load exponential moving averages into corresponding variables.\"\"\"\n",
        "\n",
        "  def __init__(self, model_dir):\n",
        "    super(LoadEMAHook, self).__init__()\n",
        "    self._model_dir = model_dir\n",
        "\n",
        "  def begin(self):\n",
        "    ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
        "    variables_to_restore = ema.variables_to_restore()\n",
        "    self._load_ema = tf.contrib.framework.assign_from_checkpoint_fn(\n",
        "        tf.train.latest_checkpoint(self._model_dir), variables_to_restore)\n",
        "\n",
        "  def after_create_session(self, sess, coord):\n",
        "    tf.logging.info('Reloading EMA...')\n",
        "    self._load_ema(sess)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "atKLBN6BwJaZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def do_it(mode):\n",
        "  params = {\n",
        "      'input_perm': [0, 1, 2, 3],\n",
        "      'output_perm': [0, 1, 2, 3],\n",
        "      'warmup': mode=='warmup',\n",
        "      'mode': mode,\n",
        "  }\n",
        "\n",
        "  if mode == 'retrain':\n",
        "    # wipe checkpoints\n",
        "    files=tf.gfile.ListDirectory(model_dir)\n",
        "    for f in files:\n",
        "        fname=model_dir+f\n",
        "        fs = tf.gfile.Stat(fname)\n",
        "        if not fs.is_directory:\n",
        "            tf.gfile.Remove(fname)\n",
        "\n",
        "    do_it('warmup')\n",
        "    do_it('train')\n",
        "  if mode == 'warmup':\n",
        "    mode = 'train'\n",
        "  if mode == 'retrain_and_eval':\n",
        "    # wipe checkpoints\n",
        "    files=tf.gfile.ListDirectory(model_dir)\n",
        "    for f in files:\n",
        "        fname=model_dir+f\n",
        "        fs = tf.gfile.Stat(fname)\n",
        "        if not fs.is_directory:\n",
        "            tf.gfile.Remove(fname)\n",
        "    do_it('warmup')\n",
        "    do_it('train_and_eval')\n",
        "\n",
        "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "  tf.logging.info('Precision: %s', precision)\n",
        "\n",
        "  if mode == 'predict':\n",
        "        batch_axis=None\n",
        "  else:\n",
        "    batch_axis = 0\n",
        "    if transpose_enabled:\n",
        "        params['input_perm'] = [3, 0, 1, 2]\n",
        "        params['output_perm'] = [1, 2, 3, 0]\n",
        "        batch_axis = 3\n",
        "    batch_axis=(batch_axis, 0)\n",
        "\n",
        "  eval_size = _NUM_EVAL_IMAGES\n",
        "  eval_steps = eval_size // geval_batch_size\n",
        "\n",
        "  iterations = (eval_steps if mode == 'eval' else save_summary_steps)\n",
        "\n",
        "  eval_batch_size = (None if mode == 'train' else geval_batch_size)\n",
        "\n",
        "  per_host_input_for_training = (num_shards <= 8 if mode == 'train' else True)\n",
        "\n",
        "  run_config = tf.contrib.tpu.RunConfig(\n",
        "      cluster=tpu_cluster_resolver,\n",
        "      model_dir=model_dir,\n",
        "      save_checkpoints_secs=save_checkpoints_secs,\n",
        "      save_summary_steps=save_summary_steps,\n",
        "      session_config=tf.ConfigProto(\n",
        "          allow_soft_placement=True,\n",
        "          log_device_placement=log_device_placement),\n",
        "      tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "          iterations_per_loop=iterations,\n",
        "          num_shards=num_shards,\n",
        "          per_host_input_for_training=per_host_input_for_training))\n",
        "\n",
        "  trainable_vars = tf.contrib.framework.get_model_variables()\n",
        "  #print(trainable_vars)\n",
        "  skip_vars=['InceptionV3/AuxLogits/Conv2d_2b_1x1/weights']\n",
        "  load_vars = tf.contrib.framework.filter_variables(trainable_vars, exclude_patterns=skip_vars)\n",
        "  #print(load_vars)\n",
        "  ws = tf.estimator.WarmStartSettings(\n",
        "      ckpt_to_initialize_from=DATA_DIR+\"pre-trained/inception_v3.ckpt\",\n",
        "      vars_to_warm_start=load_vars\n",
        "  )\n",
        "  inception_classifier = tf.contrib.tpu.TPUEstimator(\n",
        "      model_fn=inception_model_fn,\n",
        "      use_tpu=use_tpu,\n",
        "      config=run_config,\n",
        "      warm_start_from=ws,\n",
        "      params=params,\n",
        "      train_batch_size=train_batch_size,\n",
        "      eval_batch_size=eval_batch_size,\n",
        "      predict_batch_size=eval_batch_size,\n",
        "      batch_axis=batch_axis)\n",
        "\n",
        "  # Input pipelines are slightly different (with regards to shuffling and\n",
        "  # preprocessing) between training and evaluation.\n",
        "  use_bfloat16 = precision == 'bfloat16'\n",
        "  imagenet_train = tg\n",
        "  imagenet_eval = vg\n",
        "\n",
        "  if moving_average:\n",
        "    eval_hooks = [LoadEMAHook(model_dir)]\n",
        "  else:\n",
        "    eval_hooks = []\n",
        "\n",
        "  if mode == 'eval':\n",
        "    # Run evaluation when there is a new checkpoint\n",
        "    for checkpoint in evaluation.checkpoints_iterator(\n",
        "        model_dir, timeout=eval_timeout):\n",
        "      tf.logging.info('Starting to evaluate.')\n",
        "      try:\n",
        "        start_timestamp = time.time()  # Includes compilation time\n",
        "        eval_results = inception_classifier.evaluate(\n",
        "            input_fn=imagenet_eval.input_fn,\n",
        "            steps=eval_steps,\n",
        "            hooks=eval_hooks,\n",
        "            checkpoint_path=checkpoint)\n",
        "        elapsed_time = int(time.time() - start_timestamp)\n",
        "        tf.logging.info(\n",
        "            'Eval results: %s. Elapsed seconds: %d', eval_results, elapsed_time)\n",
        "\n",
        "        # Terminate eval job when final checkpoint is reached\n",
        "        current_step = int(os.path.basename(checkpoint).split('-')[1])\n",
        "        if current_step >= train_steps:\n",
        "          tf.logging.info(\n",
        "              'Evaluation finished after training step %d', current_step)\n",
        "          break\n",
        "      except tf.errors.NotFoundError:\n",
        "        # Since the coordinator is on a different job than the TPU worker,\n",
        "        # sometimes the TPU worker does not finish initializing until long after\n",
        "        # the CPU job tells it to start evaluating. In this case, the checkpoint\n",
        "        # file could have been deleted already.\n",
        "        tf.logging.info(\n",
        "            'Checkpoint %s no longer exists, skipping checkpoint', checkpoint)\n",
        "\n",
        "  elif mode == 'train_and_eval':\n",
        "    for cycle in range(train_steps // train_steps_per_eval):\n",
        "      tf.logging.info('Starting training cycle %d.' % cycle)\n",
        "      inception_classifier.train(\n",
        "          input_fn=imagenet_train.input_fn, steps=train_steps_per_eval)\n",
        "\n",
        "      tf.logging.info('Starting evaluation cycle %d .' % cycle)\n",
        "      eval_results = inception_classifier.evaluate(\n",
        "          input_fn=imagenet_eval.input_fn, steps=eval_steps, hooks=eval_hooks)\n",
        "      tf.logging.info('Evaluation results: %s' % eval_results)\n",
        "  elif mode == 'predict':\n",
        "    result=inception_classifier.predict(input_fn=imagenet_eval.input_fn)\n",
        "    for i, r in enumerate(result):\n",
        "        print(r)\n",
        "        if i>50:\n",
        "            break\n",
        "  else:\n",
        "    tf.logging.info('Starting training ...')\n",
        "    if params['warmup']:\n",
        "        steps = train_steps_per_eval*2 # ~2 epochs\n",
        "        print('warming up for ', steps)\n",
        "    else:\n",
        "        steps = train_steps\n",
        "        print('training for ')\n",
        "    inception_classifier.train(\n",
        "        input_fn=imagenet_train.input_fn, steps=steps)\n",
        "\n",
        "  #if export_dir is not None:\n",
        "  #  tf.logging.info('Starting to export model.')\n",
        "  #  inception_classifier.export_saved_model(\n",
        "  #      export_dir_base=export_dir,\n",
        "  #      serving_input_receiver_fn=image_serving_input_fn)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RrRGqcnH5Pem",
        "colab_type": "code",
        "outputId": "8a120a44-0bc6-45d8-c2c9-d5331d554536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34351
        }
      },
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "#tf.logging.set_verbosity(tf.logging.INFO)\n",
        "do_it('retrain')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Precision: float32\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://human-protein-atlas-kaggle/output-noaux/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 1000, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      value: \"10.85.239.50:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdc97dd26a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': b'grpc://10.85.239.50:8470', '_evaluation_master': b'grpc://10.85.239.50:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.contrib.cluster_resolver.python.training.tpu_cluster_resolver.TPUClusterResolver object at 0x7fdc97dd2828>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Starting training ...\n",
            "warming up for  388\n",
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.85.239.50:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 10946900395850354813)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2150489995054598000)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 2841688867380542543)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12311736082261458102)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16530568811090666039)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6106581041025008983)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12334059195984386793)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17934693137254689662)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 12496630498973520767)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6559484486240104935)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2283344607825868653)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 13911280868096962566)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "Tensor(\"InceptionV3/Logits/Dropout_1b/dropout/mul:0\", shape=(16, 384), dtype=float32)\n",
            "Tensor(\"InceptionV3/Logits/ExpandDims_1:0\", shape=(16, 1, 1, 384), dtype=float32)\n",
            "INFO:tensorflow:Using Adam optimizer\n",
            "Training [<tf.Variable 'InceptionV3/InceptionV3/Conv2d_1a_3x3/weights:0' shape=(3, 3, 3, 32) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Conv2d_1a_3x3/BatchNorm/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Conv2d_2a_3x3/weights:0' shape=(3, 3, 32, 32) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Conv2d_2a_3x3/BatchNorm/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Conv2d_2b_3x3/weights:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Conv2d_2b_3x3/BatchNorm/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Conv2d_3b_1x1/weights:0' shape=(1, 1, 64, 80) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Conv2d_3b_1x1/BatchNorm/beta:0' shape=(80,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Conv2d_4a_3x3/weights:0' shape=(3, 3, 80, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Conv2d_4a_3x3/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights:0' shape=(1, 1, 192, 64) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights:0' shape=(1, 1, 192, 48) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(48,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0b_5x5/weights:0' shape=(5, 5, 48, 64) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5b/Branch_1/Conv2d_0b_5x5/BatchNorm/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights:0' shape=(1, 1, 192, 64) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights:0' shape=(3, 3, 64, 96) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights:0' shape=(3, 3, 96, 96) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights:0' shape=(1, 1, 192, 32) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights:0' shape=(1, 1, 256, 64) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv2d_0b_1x1/weights:0' shape=(1, 1, 256, 48) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv2d_0b_1x1/BatchNorm/beta:0' shape=(48,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv_1_0c_5x5/weights:0' shape=(5, 5, 48, 64) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5c/Branch_1/Conv_1_0c_5x5/BatchNorm/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights:0' shape=(1, 1, 256, 64) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights:0' shape=(3, 3, 64, 96) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights:0' shape=(3, 3, 96, 96) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights:0' shape=(1, 1, 256, 64) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5d/Branch_0/Conv2d_0a_1x1/weights:0' shape=(1, 1, 288, 64) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5d/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0a_1x1/weights:0' shape=(1, 1, 288, 48) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(48,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0b_5x5/weights:0' shape=(5, 5, 48, 64) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5d/Branch_1/Conv2d_0b_5x5/BatchNorm/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0a_1x1/weights:0' shape=(1, 1, 288, 64) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0b_3x3/weights:0' shape=(3, 3, 64, 96) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0b_3x3/BatchNorm/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0c_3x3/weights:0' shape=(3, 3, 96, 96) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5d/Branch_2/Conv2d_0c_3x3/BatchNorm/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5d/Branch_3/Conv2d_0b_1x1/weights:0' shape=(1, 1, 288, 64) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_5d/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6a/Branch_0/Conv2d_1a_1x1/weights:0' shape=(3, 3, 288, 384) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6a/Branch_0/Conv2d_1a_1x1/BatchNorm/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0a_1x1/weights:0' shape=(1, 1, 288, 64) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0b_3x3/weights:0' shape=(3, 3, 64, 96) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_0b_3x3/BatchNorm/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_1a_1x1/weights:0' shape=(3, 3, 96, 96) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6a/Branch_1/Conv2d_1a_1x1/BatchNorm/beta:0' shape=(96,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_0/Conv2d_0a_1x1/weights:0' shape=(1, 1, 768, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0a_1x1/weights:0' shape=(1, 1, 768, 128) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(128,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0b_1x7/weights:0' shape=(1, 7, 128, 128) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0b_1x7/BatchNorm/beta:0' shape=(128,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0c_7x1/weights:0' shape=(7, 1, 128, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_1/Conv2d_0c_7x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0a_1x1/weights:0' shape=(1, 1, 768, 128) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(128,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0b_7x1/weights:0' shape=(7, 1, 128, 128) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0b_7x1/BatchNorm/beta:0' shape=(128,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0c_1x7/weights:0' shape=(1, 7, 128, 128) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0c_1x7/BatchNorm/beta:0' shape=(128,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0d_7x1/weights:0' shape=(7, 1, 128, 128) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0d_7x1/BatchNorm/beta:0' shape=(128,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0e_1x7/weights:0' shape=(1, 7, 128, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_2/Conv2d_0e_1x7/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_3/Conv2d_0b_1x1/weights:0' shape=(1, 1, 768, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6b/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_0/Conv2d_0a_1x1/weights:0' shape=(1, 1, 768, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0a_1x1/weights:0' shape=(1, 1, 768, 160) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0b_1x7/weights:0' shape=(1, 7, 160, 160) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0b_1x7/BatchNorm/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0c_7x1/weights:0' shape=(7, 1, 160, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_1/Conv2d_0c_7x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0a_1x1/weights:0' shape=(1, 1, 768, 160) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0b_7x1/weights:0' shape=(7, 1, 160, 160) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0b_7x1/BatchNorm/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0c_1x7/weights:0' shape=(1, 7, 160, 160) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0c_1x7/BatchNorm/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0d_7x1/weights:0' shape=(7, 1, 160, 160) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0d_7x1/BatchNorm/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0e_1x7/weights:0' shape=(1, 7, 160, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_2/Conv2d_0e_1x7/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_3/Conv2d_0b_1x1/weights:0' shape=(1, 1, 768, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6c/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_0/Conv2d_0a_1x1/weights:0' shape=(1, 1, 768, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0a_1x1/weights:0' shape=(1, 1, 768, 160) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0b_1x7/weights:0' shape=(1, 7, 160, 160) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0b_1x7/BatchNorm/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/weights:0' shape=(7, 1, 160, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0a_1x1/weights:0' shape=(1, 1, 768, 160) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0b_7x1/weights:0' shape=(7, 1, 160, 160) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0b_7x1/BatchNorm/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/weights:0' shape=(1, 7, 160, 160) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/BatchNorm/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0d_7x1/weights:0' shape=(7, 1, 160, 160) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0d_7x1/BatchNorm/beta:0' shape=(160,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0e_1x7/weights:0' shape=(1, 7, 160, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_2/Conv2d_0e_1x7/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_3/Conv2d_0b_1x1/weights:0' shape=(1, 1, 768, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6d/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_0/Conv2d_0a_1x1/weights:0' shape=(1, 1, 768, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0a_1x1/weights:0' shape=(1, 1, 768, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0b_1x7/weights:0' shape=(1, 7, 192, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0b_1x7/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0c_7x1/weights:0' shape=(7, 1, 192, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_1/Conv2d_0c_7x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0a_1x1/weights:0' shape=(1, 1, 768, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0b_7x1/weights:0' shape=(7, 1, 192, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0b_7x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0c_1x7/weights:0' shape=(1, 7, 192, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0c_1x7/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0d_7x1/weights:0' shape=(7, 1, 192, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0d_7x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0e_1x7/weights:0' shape=(1, 7, 192, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_2/Conv2d_0e_1x7/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_3/Conv2d_0b_1x1/weights:0' shape=(1, 1, 768, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_6e/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/weights:0' shape=(1, 1, 768, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/weights:0' shape=(3, 3, 192, 320) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7a/Branch_0/Conv2d_1a_3x3/BatchNorm/beta:0' shape=(320,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/weights:0' shape=(1, 1, 768, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/weights:0' shape=(1, 7, 192, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0b_1x7/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/weights:0' shape=(7, 1, 192, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_0c_7x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/weights:0' shape=(3, 3, 192, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7a/Branch_1/Conv2d_1a_3x3/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/weights:0' shape=(1, 1, 1280, 320) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(320,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/weights:0' shape=(1, 1, 1280, 384) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/weights:0' shape=(1, 3, 384, 384) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_1x3/BatchNorm/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/weights:0' shape=(3, 1, 384, 384) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_1/Conv2d_0b_3x1/BatchNorm/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/weights:0' shape=(1, 1, 1280, 448) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(448,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/weights:0' shape=(3, 3, 448, 384) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0b_3x3/BatchNorm/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/weights:0' shape=(1, 3, 384, 384) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0c_1x3/BatchNorm/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/weights:0' shape=(3, 1, 384, 384) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_2/Conv2d_0d_3x1/BatchNorm/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/weights:0' shape=(1, 1, 1280, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7b/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/weights:0' shape=(1, 1, 2048, 320) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_0/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(320,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/weights:0' shape=(1, 1, 2048, 384) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/weights:0' shape=(1, 3, 384, 384) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0b_1x3/BatchNorm/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/weights:0' shape=(3, 1, 384, 384) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_1/Conv2d_0c_3x1/BatchNorm/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/weights:0' shape=(1, 1, 2048, 448) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0a_1x1/BatchNorm/beta:0' shape=(448,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/weights:0' shape=(3, 3, 448, 384) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0b_3x3/BatchNorm/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/weights:0' shape=(1, 3, 384, 384) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0c_1x3/BatchNorm/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/weights:0' shape=(3, 1, 384, 384) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_2/Conv2d_0d_3x1/BatchNorm/beta:0' shape=(384,) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/weights:0' shape=(1, 1, 2048, 192) dtype=float32>, <tf.Variable 'InceptionV3/InceptionV3/Mixed_7c/Branch_3/Conv2d_0b_1x1/BatchNorm/beta:0' shape=(192,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7b_rnn/width/lstm_cell/kernel:0' shape=(2112, 256) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7b_rnn/width/lstm_cell/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7b_rnn/width/lstm_cell/w_f_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7b_rnn/width/lstm_cell/w_i_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7b_rnn/width/lstm_cell/w_o_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7b_rnn/height/lstm_cell/kernel:0' shape=(2112, 256) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7b_rnn/height/lstm_cell/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7b_rnn/height/lstm_cell/w_f_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7b_rnn/height/lstm_cell/w_i_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7b_rnn/height/lstm_cell/w_o_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7a_rnn/width/lstm_cell/kernel:0' shape=(1344, 256) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7a_rnn/width/lstm_cell/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7a_rnn/width/lstm_cell/w_f_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7a_rnn/width/lstm_cell/w_i_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7a_rnn/width/lstm_cell/w_o_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7a_rnn/height/lstm_cell/kernel:0' shape=(1344, 256) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7a_rnn/height/lstm_cell/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7a_rnn/height/lstm_cell/w_f_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7a_rnn/height/lstm_cell/w_i_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_7a_rnn/height/lstm_cell/w_o_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_6e_rnn/width/lstm_cell/kernel:0' shape=(832, 256) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_6e_rnn/width/lstm_cell/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_6e_rnn/width/lstm_cell/w_f_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_6e_rnn/width/lstm_cell/w_i_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_6e_rnn/width/lstm_cell/w_o_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_6e_rnn/height/lstm_cell/kernel:0' shape=(832, 256) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_6e_rnn/height/lstm_cell/bias:0' shape=(256,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_6e_rnn/height/lstm_cell/w_f_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_6e_rnn/height/lstm_cell/w_i_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Mixed_6e_rnn/height/lstm_cell/w_o_diag:0' shape=(64,) dtype=float32>, <tf.Variable 'InceptionV3/Logits/Conv2d_1c_1x1/weights:0' shape=(1, 1, 384, 28) dtype=float32>, <tf.Variable 'InceptionV3/Logits/Conv2d_1c_1x1/biases:0' shape=(28,) dtype=float32>]\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='gs://human-protein-atlas-kaggle/pre-trained/inception_v3.ckpt', vars_to_warm_start=[], var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
            "INFO:tensorflow:Warm-starting from: ('gs://human-protein-atlas-kaggle/pre-trained/inception_v3.ckpt',)\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into gs://human-protein-atlas-kaggle/output-noaux/model.ckpt.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 4 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 19.197721, step = 100\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 6.067511, step = 200 (27.872 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.58823\n",
            "INFO:tensorflow:examples/sec: 459.293\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 3.053013, step = 300 (18.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4859\n",
            "INFO:tensorflow:examples/sec: 702.195\n",
            "INFO:tensorflow:Enqueue next (88) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (88) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 1.9383472, step = 388 (16.292 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 388 into gs://human-protein-atlas-kaggle/output-noaux/model.ckpt.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Loss for final step: 1.9383472.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "INFO:tensorflow:Precision: float32\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://human-protein-atlas-kaggle/output-noaux/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 1000, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      value: \"10.85.239.50:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdc9528cac8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': b'grpc://10.85.239.50:8470', '_evaluation_master': b'grpc://10.85.239.50:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.contrib.cluster_resolver.python.training.tpu_cluster_resolver.TPUClusterResolver object at 0x7fdc99b28550>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Starting training ...\n",
            "training for \n",
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.85.239.50:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 10946900395850354813)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2150489995054598000)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 2841688867380542543)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12311736082261458102)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16530568811090666039)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6106581041025008983)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12334059195984386793)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17934693137254689662)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 12496630498973520767)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6559484486240104935)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2283344607825868653)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 13911280868096962566)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "Tensor(\"InceptionV3/Logits/Dropout_1b/dropout/mul:0\", shape=(16, 384), dtype=float32)\n",
            "Tensor(\"InceptionV3/Logits/ExpandDims_1:0\", shape=(16, 1, 1, 384), dtype=float32)\n",
            "INFO:tensorflow:Using Adam optimizer\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='gs://human-protein-atlas-kaggle/pre-trained/inception_v3.ckpt', vars_to_warm_start=[], var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
            "INFO:tensorflow:Warm-starting from: ('gs://human-protein-atlas-kaggle/pre-trained/inception_v3.ckpt',)\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://human-protein-atlas-kaggle/output-noaux/model.ckpt-388\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 388 into gs://human-protein-atlas-kaggle/output-noaux/model.ckpt.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 8 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 1.3795826, step = 488\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.9464037, step = 588 (28.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.51781\n",
            "INFO:tensorflow:examples/sec: 450.28\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.7976512, step = 688 (18.269 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47394\n",
            "INFO:tensorflow:examples/sec: 700.665\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.59479654, step = 788 (18.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48396\n",
            "INFO:tensorflow:examples/sec: 701.946\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.4649606, step = 888 (18.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48259\n",
            "INFO:tensorflow:examples/sec: 701.771\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.49814403, step = 988 (18.250 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47948\n",
            "INFO:tensorflow:examples/sec: 701.373\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.3345293, step = 1088 (19.445 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.14251\n",
            "INFO:tensorflow:examples/sec: 658.241\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.29844567, step = 1188 (18.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49437\n",
            "INFO:tensorflow:examples/sec: 703.28\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.29412618, step = 1288 (18.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50187\n",
            "INFO:tensorflow:examples/sec: 704.239\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.27536798, step = 1388 (18.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49805\n",
            "INFO:tensorflow:examples/sec: 703.75\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.24948052, step = 1488 (18.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48363\n",
            "INFO:tensorflow:examples/sec: 701.904\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.24933538, step = 1588 (18.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49958\n",
            "INFO:tensorflow:examples/sec: 703.947\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.31859237, step = 1688 (18.208 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4923\n",
            "INFO:tensorflow:examples/sec: 703.015\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20592442, step = 1788 (18.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4982\n",
            "INFO:tensorflow:examples/sec: 703.77\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.24122293, step = 1888 (19.020 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.25661\n",
            "INFO:tensorflow:examples/sec: 672.846\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.22869353, step = 1988 (18.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47798\n",
            "INFO:tensorflow:examples/sec: 701.181\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21392564, step = 2088 (18.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48471\n",
            "INFO:tensorflow:examples/sec: 702.043\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.26112318, step = 2188 (18.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49944\n",
            "INFO:tensorflow:examples/sec: 703.928\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.25759286, step = 2288 (18.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49327\n",
            "INFO:tensorflow:examples/sec: 703.138\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.28145373, step = 2388 (18.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.51096\n",
            "INFO:tensorflow:examples/sec: 705.403\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18884258, step = 2488 (18.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49743\n",
            "INFO:tensorflow:examples/sec: 703.671\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2443018, step = 2588 (19.610 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.09967\n",
            "INFO:tensorflow:examples/sec: 652.757\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18160123, step = 2688 (18.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50011\n",
            "INFO:tensorflow:examples/sec: 704.014\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20497312, step = 2788 (18.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50886\n",
            "INFO:tensorflow:examples/sec: 705.134\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17725958, step = 2888 (18.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49541\n",
            "INFO:tensorflow:examples/sec: 703.412\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.24186434, step = 2988 (18.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48443\n",
            "INFO:tensorflow:examples/sec: 702.007\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1607768, step = 3088 (18.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50293\n",
            "INFO:tensorflow:examples/sec: 704.375\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.24411514, step = 3188 (19.292 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.18365\n",
            "INFO:tensorflow:examples/sec: 663.507\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17915477, step = 3288 (18.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.485\n",
            "INFO:tensorflow:examples/sec: 702.081\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17944731, step = 3388 (18.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.51072\n",
            "INFO:tensorflow:examples/sec: 705.372\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.24533126, step = 3488 (18.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46578\n",
            "INFO:tensorflow:examples/sec: 699.62\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.24213666, step = 3588 (18.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50669\n",
            "INFO:tensorflow:examples/sec: 704.856\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20954646, step = 3688 (18.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50035\n",
            "INFO:tensorflow:examples/sec: 704.045\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19578409, step = 3788 (18.340 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4529\n",
            "INFO:tensorflow:examples/sec: 697.971\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17269231, step = 3888 (18.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46786\n",
            "INFO:tensorflow:examples/sec: 699.886\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.208407, step = 3988 (19.359 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.16548\n",
            "INFO:tensorflow:examples/sec: 661.181\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1870767, step = 4088 (18.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48104\n",
            "INFO:tensorflow:examples/sec: 701.573\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19296828, step = 4188 (18.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48787\n",
            "INFO:tensorflow:examples/sec: 702.447\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18775915, step = 4288 (18.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48558\n",
            "INFO:tensorflow:examples/sec: 702.154\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19966538, step = 4388 (18.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49784\n",
            "INFO:tensorflow:examples/sec: 703.724\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17807771, step = 4488 (18.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48745\n",
            "INFO:tensorflow:examples/sec: 702.393\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.25365683, step = 4588 (18.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48967\n",
            "INFO:tensorflow:examples/sec: 702.678\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21257758, step = 4688 (19.001 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.26301\n",
            "INFO:tensorflow:examples/sec: 673.665\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19576734, step = 4788 (18.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50317\n",
            "INFO:tensorflow:examples/sec: 704.406\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1858498, step = 4888 (18.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49631\n",
            "INFO:tensorflow:examples/sec: 703.527\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16177373, step = 4988 (18.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46727\n",
            "INFO:tensorflow:examples/sec: 699.811\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21279174, step = 5088 (18.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48005\n",
            "INFO:tensorflow:examples/sec: 701.447\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21922694, step = 5188 (18.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47324\n",
            "INFO:tensorflow:examples/sec: 700.574\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 5288 into gs://human-protein-atlas-kaggle/output-noaux/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.2265373, step = 5288 (30.410 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.28794\n",
            "INFO:tensorflow:examples/sec: 420.856\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19526197, step = 5388 (18.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49264\n",
            "INFO:tensorflow:examples/sec: 703.058\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16757314, step = 5488 (18.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49589\n",
            "INFO:tensorflow:examples/sec: 703.474\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.23340195, step = 5588 (18.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49393\n",
            "INFO:tensorflow:examples/sec: 703.223\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18546349, step = 5688 (18.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50406\n",
            "INFO:tensorflow:examples/sec: 704.519\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21804692, step = 5788 (18.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49681\n",
            "INFO:tensorflow:examples/sec: 703.592\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21717446, step = 5888 (18.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4959\n",
            "INFO:tensorflow:examples/sec: 703.475\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18859182, step = 5988 (18.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48745\n",
            "INFO:tensorflow:examples/sec: 702.393\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2634428, step = 6088 (18.998 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.26291\n",
            "INFO:tensorflow:examples/sec: 673.653\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19616503, step = 6188 (18.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50059\n",
            "INFO:tensorflow:examples/sec: 704.075\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2118461, step = 6288 (18.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50302\n",
            "INFO:tensorflow:examples/sec: 704.386\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.22897749, step = 6388 (18.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48533\n",
            "INFO:tensorflow:examples/sec: 702.123\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.26961806, step = 6488 (18.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50581\n",
            "INFO:tensorflow:examples/sec: 704.743\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21158202, step = 6588 (18.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.45864\n",
            "INFO:tensorflow:examples/sec: 698.705\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.22725825, step = 6688 (18.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.51364\n",
            "INFO:tensorflow:examples/sec: 705.746\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18472873, step = 6788 (19.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.1787\n",
            "INFO:tensorflow:examples/sec: 662.873\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18216571, step = 6888 (18.591 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.37982\n",
            "INFO:tensorflow:examples/sec: 688.618\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18735501, step = 6988 (18.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50162\n",
            "INFO:tensorflow:examples/sec: 704.208\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18931612, step = 7088 (18.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48974\n",
            "INFO:tensorflow:examples/sec: 702.687\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18446557, step = 7188 (18.244 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48111\n",
            "INFO:tensorflow:examples/sec: 701.582\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17836049, step = 7288 (18.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46743\n",
            "INFO:tensorflow:examples/sec: 699.831\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.23242825, step = 7388 (19.079 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.24058\n",
            "INFO:tensorflow:examples/sec: 670.794\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16526684, step = 7488 (18.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49854\n",
            "INFO:tensorflow:examples/sec: 703.813\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19604525, step = 7588 (18.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49481\n",
            "INFO:tensorflow:examples/sec: 703.336\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16688453, step = 7688 (18.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50137\n",
            "INFO:tensorflow:examples/sec: 704.175\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18452755, step = 7788 (18.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50155\n",
            "INFO:tensorflow:examples/sec: 704.199\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20326191, step = 7888 (18.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50172\n",
            "INFO:tensorflow:examples/sec: 704.22\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17369151, step = 7988 (18.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49996\n",
            "INFO:tensorflow:examples/sec: 703.995\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21102983, step = 8088 (18.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4939\n",
            "INFO:tensorflow:examples/sec: 703.22\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2181537, step = 8188 (19.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.22154\n",
            "INFO:tensorflow:examples/sec: 668.358\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17351198, step = 8288 (18.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46789\n",
            "INFO:tensorflow:examples/sec: 699.89\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.22588941, step = 8388 (18.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46217\n",
            "INFO:tensorflow:examples/sec: 699.158\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20524022, step = 8488 (18.250 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48032\n",
            "INFO:tensorflow:examples/sec: 701.482\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17108122, step = 8588 (18.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47541\n",
            "INFO:tensorflow:examples/sec: 700.853\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17457978, step = 8688 (18.267 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47423\n",
            "INFO:tensorflow:examples/sec: 700.701\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20738274, step = 8788 (18.243 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48158\n",
            "INFO:tensorflow:examples/sec: 701.642\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19009809, step = 8888 (18.998 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.26361\n",
            "INFO:tensorflow:examples/sec: 673.742\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20134917, step = 8988 (18.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49944\n",
            "INFO:tensorflow:examples/sec: 703.928\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16644359, step = 9088 (18.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50873\n",
            "INFO:tensorflow:examples/sec: 705.118\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16094214, step = 9188 (18.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49478\n",
            "INFO:tensorflow:examples/sec: 703.332\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18266743, step = 9288 (18.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49972\n",
            "INFO:tensorflow:examples/sec: 703.965\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18804227, step = 9388 (18.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49771\n",
            "INFO:tensorflow:examples/sec: 703.707\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18290061, step = 9488 (19.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.23158\n",
            "INFO:tensorflow:examples/sec: 669.643\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20054208, step = 9588 (18.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50804\n",
            "INFO:tensorflow:examples/sec: 705.029\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21343572, step = 9688 (18.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4805\n",
            "INFO:tensorflow:examples/sec: 701.504\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17998625, step = 9788 (18.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50443\n",
            "INFO:tensorflow:examples/sec: 704.566\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2007033, step = 9888 (18.330 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.45585\n",
            "INFO:tensorflow:examples/sec: 698.348\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.15598324, step = 9988 (18.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.51912\n",
            "INFO:tensorflow:examples/sec: 706.448\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18761759, step = 10088 (18.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48062\n",
            "INFO:tensorflow:examples/sec: 701.52\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.23899621, step = 10188 (18.794 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.32086\n",
            "INFO:tensorflow:examples/sec: 681.071\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18537854, step = 10288 (18.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.27522\n",
            "INFO:tensorflow:examples/sec: 675.229\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16659673, step = 10388 (18.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46547\n",
            "INFO:tensorflow:examples/sec: 699.58\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18246141, step = 10488 (18.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47148\n",
            "INFO:tensorflow:examples/sec: 700.349\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17170578, step = 10588 (18.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4493\n",
            "INFO:tensorflow:examples/sec: 697.511\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 10688 into gs://human-protein-atlas-kaggle/output-noaux/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.16992262, step = 10688 (28.510 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.50752\n",
            "INFO:tensorflow:examples/sec: 448.963\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.24533978, step = 10788 (18.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49938\n",
            "INFO:tensorflow:examples/sec: 703.921\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18702735, step = 10888 (18.884 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.29586\n",
            "INFO:tensorflow:examples/sec: 677.87\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.23820958, step = 10988 (18.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48353\n",
            "INFO:tensorflow:examples/sec: 701.891\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.22477952, step = 11088 (18.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49695\n",
            "INFO:tensorflow:examples/sec: 703.61\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18410763, step = 11188 (18.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50536\n",
            "INFO:tensorflow:examples/sec: 704.686\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19128843, step = 11288 (18.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49053\n",
            "INFO:tensorflow:examples/sec: 702.788\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1812837, step = 11388 (18.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49337\n",
            "INFO:tensorflow:examples/sec: 703.151\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16415465, step = 11488 (18.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48723\n",
            "INFO:tensorflow:examples/sec: 702.366\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19726843, step = 11588 (19.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.21689\n",
            "INFO:tensorflow:examples/sec: 667.761\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16827323, step = 11688 (18.269 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4746\n",
            "INFO:tensorflow:examples/sec: 700.748\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18425117, step = 11788 (18.223 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48762\n",
            "INFO:tensorflow:examples/sec: 702.416\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20881107, step = 11888 (18.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48993\n",
            "INFO:tensorflow:examples/sec: 702.711\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2078133, step = 11988 (18.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49702\n",
            "INFO:tensorflow:examples/sec: 703.619\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20463207, step = 12088 (18.226 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48694\n",
            "INFO:tensorflow:examples/sec: 702.328\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20155747, step = 12188 (19.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.20499\n",
            "INFO:tensorflow:examples/sec: 666.238\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16171375, step = 12288 (18.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50093\n",
            "INFO:tensorflow:examples/sec: 704.118\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18945317, step = 12388 (18.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49667\n",
            "INFO:tensorflow:examples/sec: 703.574\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.15107462, step = 12488 (18.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48913\n",
            "INFO:tensorflow:examples/sec: 702.609\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18861681, step = 12588 (18.232 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48381\n",
            "INFO:tensorflow:examples/sec: 701.927\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20239407, step = 12688 (18.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49468\n",
            "INFO:tensorflow:examples/sec: 703.319\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20396747, step = 12788 (18.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4922\n",
            "INFO:tensorflow:examples/sec: 703.001\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1962639, step = 12888 (18.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50331\n",
            "INFO:tensorflow:examples/sec: 704.424\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19874144, step = 12988 (19.417 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.14997\n",
            "INFO:tensorflow:examples/sec: 659.196\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.22416794, step = 13088 (18.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.51072\n",
            "INFO:tensorflow:examples/sec: 705.372\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17717184, step = 13188 (18.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47187\n",
            "INFO:tensorflow:examples/sec: 700.399\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16955413, step = 13288 (18.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49811\n",
            "INFO:tensorflow:examples/sec: 703.758\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19441465, step = 13388 (18.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50418\n",
            "INFO:tensorflow:examples/sec: 704.535\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1668127, step = 13488 (18.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49311\n",
            "INFO:tensorflow:examples/sec: 703.118\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18376915, step = 13588 (18.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50619\n",
            "INFO:tensorflow:examples/sec: 704.792\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.15206835, step = 13688 (19.042 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.25165\n",
            "INFO:tensorflow:examples/sec: 672.212\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18139154, step = 13788 (18.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50387\n",
            "INFO:tensorflow:examples/sec: 704.496\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19243345, step = 13888 (18.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48341\n",
            "INFO:tensorflow:examples/sec: 701.876\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20607494, step = 13988 (18.241 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48303\n",
            "INFO:tensorflow:examples/sec: 701.828\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.15945329, step = 14088 (18.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49395\n",
            "INFO:tensorflow:examples/sec: 703.226\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18488094, step = 14188 (18.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49955\n",
            "INFO:tensorflow:examples/sec: 703.942\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18411785, step = 14288 (18.832 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.31006\n",
            "INFO:tensorflow:examples/sec: 679.687\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21253753, step = 14388 (18.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50422\n",
            "INFO:tensorflow:examples/sec: 704.541\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19903477, step = 14488 (18.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49318\n",
            "INFO:tensorflow:examples/sec: 703.127\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18719013, step = 14588 (18.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50154\n",
            "INFO:tensorflow:examples/sec: 704.197\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18185134, step = 14688 (18.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46247\n",
            "INFO:tensorflow:examples/sec: 699.196\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21403608, step = 14788 (18.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48065\n",
            "INFO:tensorflow:examples/sec: 701.524\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19406238, step = 14888 (18.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46726\n",
            "INFO:tensorflow:examples/sec: 699.809\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18252432, step = 14988 (18.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47922\n",
            "INFO:tensorflow:examples/sec: 701.34\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19069542, step = 15088 (19.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.21839\n",
            "INFO:tensorflow:examples/sec: 667.954\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19967972, step = 15188 (18.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49472\n",
            "INFO:tensorflow:examples/sec: 703.325\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20423938, step = 15288 (18.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48616\n",
            "INFO:tensorflow:examples/sec: 702.229\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18409842, step = 15388 (18.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49888\n",
            "INFO:tensorflow:examples/sec: 703.857\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2120783, step = 15488 (18.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49503\n",
            "INFO:tensorflow:examples/sec: 703.363\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19102712, step = 15588 (18.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49992\n",
            "INFO:tensorflow:examples/sec: 703.99\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2036807, step = 15688 (18.206 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49283\n",
            "INFO:tensorflow:examples/sec: 703.082\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17743476, step = 15788 (19.224 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.20203\n",
            "INFO:tensorflow:examples/sec: 665.859\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17732696, step = 15888 (18.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49759\n",
            "INFO:tensorflow:examples/sec: 703.692\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1809279, step = 15988 (18.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50231\n",
            "INFO:tensorflow:examples/sec: 704.296\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 16088 into gs://human-protein-atlas-kaggle/output-noaux/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.20291512, step = 16088 (28.030 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.56747\n",
            "INFO:tensorflow:examples/sec: 456.636\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19915748, step = 16188 (18.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.5079\n",
            "INFO:tensorflow:examples/sec: 705.011\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17800964, step = 16288 (18.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47106\n",
            "INFO:tensorflow:examples/sec: 700.296\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19228455, step = 16388 (19.033 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.2542\n",
            "INFO:tensorflow:examples/sec: 672.537\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18512332, step = 16488 (18.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46925\n",
            "INFO:tensorflow:examples/sec: 700.064\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19956894, step = 16588 (18.549 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.39111\n",
            "INFO:tensorflow:examples/sec: 690.062\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19555414, step = 16688 (18.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49433\n",
            "INFO:tensorflow:examples/sec: 703.274\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16268541, step = 16788 (18.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47588\n",
            "INFO:tensorflow:examples/sec: 700.913\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17668463, step = 16888 (18.265 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47507\n",
            "INFO:tensorflow:examples/sec: 700.809\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1859498, step = 16988 (20.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 4.96789\n",
            "INFO:tensorflow:examples/sec: 635.889\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18046714, step = 17088 (18.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49794\n",
            "INFO:tensorflow:examples/sec: 703.737\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17747003, step = 17188 (18.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46762\n",
            "INFO:tensorflow:examples/sec: 699.856\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2149088, step = 17288 (18.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46941\n",
            "INFO:tensorflow:examples/sec: 700.085\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19469807, step = 17388 (18.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48377\n",
            "INFO:tensorflow:examples/sec: 701.923\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.22914276, step = 17488 (18.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49609\n",
            "INFO:tensorflow:examples/sec: 703.5\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18512136, step = 17588 (18.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49674\n",
            "INFO:tensorflow:examples/sec: 703.582\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.15182376, step = 17688 (18.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49695\n",
            "INFO:tensorflow:examples/sec: 703.609\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20608257, step = 17788 (18.864 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.30093\n",
            "INFO:tensorflow:examples/sec: 678.519\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18129538, step = 17888 (18.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50158\n",
            "INFO:tensorflow:examples/sec: 704.203\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2150534, step = 17988 (18.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47819\n",
            "INFO:tensorflow:examples/sec: 701.208\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16326854, step = 18088 (18.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4621\n",
            "INFO:tensorflow:examples/sec: 699.149\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19199923, step = 18188 (18.303 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46373\n",
            "INFO:tensorflow:examples/sec: 699.357\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18811761, step = 18288 (18.271 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47306\n",
            "INFO:tensorflow:examples/sec: 700.552\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21892786, step = 18388 (18.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48294\n",
            "INFO:tensorflow:examples/sec: 701.817\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.24556871, step = 18488 (19.021 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.25728\n",
            "INFO:tensorflow:examples/sec: 672.932\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17775106, step = 18588 (18.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50438\n",
            "INFO:tensorflow:examples/sec: 704.56\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17430674, step = 18688 (18.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49503\n",
            "INFO:tensorflow:examples/sec: 703.364\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19168045, step = 18788 (18.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50054\n",
            "INFO:tensorflow:examples/sec: 704.069\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2441043, step = 18888 (18.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49413\n",
            "INFO:tensorflow:examples/sec: 703.249\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18526575, step = 18988 (18.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50554\n",
            "INFO:tensorflow:examples/sec: 704.709\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18930763, step = 19088 (19.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.23496\n",
            "INFO:tensorflow:examples/sec: 670.075\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16208185, step = 19188 (18.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50408\n",
            "INFO:tensorflow:examples/sec: 704.522\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.15878756, step = 19288 (18.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.51376\n",
            "INFO:tensorflow:examples/sec: 705.762\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19810176, step = 19388 (18.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47826\n",
            "INFO:tensorflow:examples/sec: 701.217\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21145266, step = 19488 (18.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.51283\n",
            "INFO:tensorflow:examples/sec: 705.642\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16879773, step = 19588 (18.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46901\n",
            "INFO:tensorflow:examples/sec: 700.034\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1780221, step = 19688 (18.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50278\n",
            "INFO:tensorflow:examples/sec: 704.356\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19731578, step = 19788 (18.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46806\n",
            "INFO:tensorflow:examples/sec: 699.912\n",
            "INFO:tensorflow:Enqueue next (20) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (20) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.14095864, step = 19808 (5.719 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 19808 into gs://human-protein-atlas-kaggle/output-noaux/model.ckpt.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Loss for final step: 0.14095864.\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "INFO:tensorflow:Precision: float32\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://human-protein-atlas-kaggle/output-noaux/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 1000, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      value: \"10.85.239.50:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdc846ca400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': b'grpc://10.85.239.50:8470', '_evaluation_master': b'grpc://10.85.239.50:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.contrib.cluster_resolver.python.training.tpu_cluster_resolver.TPUClusterResolver object at 0x7fdc97d31b70>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Starting training ...\n",
            "training for \n",
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.85.239.50:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 10946900395850354813)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2150489995054598000)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 2841688867380542543)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12311736082261458102)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16530568811090666039)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 6106581041025008983)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12334059195984386793)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17934693137254689662)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 12496630498973520767)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6559484486240104935)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2283344607825868653)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 13911280868096962566)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "Tensor(\"InceptionV3/Logits/Dropout_1b/dropout/mul:0\", shape=(16, 384), dtype=float32)\n",
            "Tensor(\"InceptionV3/Logits/ExpandDims_1:0\", shape=(16, 1, 1, 384), dtype=float32)\n",
            "INFO:tensorflow:Using Adam optimizer\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='gs://human-protein-atlas-kaggle/pre-trained/inception_v3.ckpt', vars_to_warm_start=[], var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
            "INFO:tensorflow:Warm-starting from: ('gs://human-protein-atlas-kaggle/pre-trained/inception_v3.ckpt',)\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://human-protein-atlas-kaggle/output-noaux/model.ckpt-19808\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 19808 into gs://human-protein-atlas-kaggle/output-noaux/model.ckpt.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:tpu_worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 8 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1721259, step = 19908\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.15388626, step = 20008 (28.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.53386\n",
            "INFO:tensorflow:examples/sec: 452.334\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19890714, step = 20108 (18.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47001\n",
            "INFO:tensorflow:examples/sec: 700.161\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18314846, step = 20208 (18.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46442\n",
            "INFO:tensorflow:examples/sec: 699.445\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20137958, step = 20308 (18.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47156\n",
            "INFO:tensorflow:examples/sec: 700.36\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17657048, step = 20408 (18.242 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48196\n",
            "INFO:tensorflow:examples/sec: 701.691\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16483974, step = 20508 (19.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.23951\n",
            "INFO:tensorflow:examples/sec: 670.657\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21060418, step = 20608 (18.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48417\n",
            "INFO:tensorflow:examples/sec: 701.974\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18843, step = 20708 (18.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49624\n",
            "INFO:tensorflow:examples/sec: 703.518\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17256458, step = 20808 (18.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49641\n",
            "INFO:tensorflow:examples/sec: 703.54\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20473409, step = 20908 (18.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48819\n",
            "INFO:tensorflow:examples/sec: 702.488\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21948282, step = 21008 (18.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49376\n",
            "INFO:tensorflow:examples/sec: 703.201\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16025417, step = 21108 (18.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50031\n",
            "INFO:tensorflow:examples/sec: 704.04\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18342824, step = 21208 (18.227 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48621\n",
            "INFO:tensorflow:examples/sec: 702.235\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.22634168, step = 21308 (19.382 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.15939\n",
            "INFO:tensorflow:examples/sec: 660.402\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.14471026, step = 21408 (18.209 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49199\n",
            "INFO:tensorflow:examples/sec: 702.975\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1875462, step = 21508 (18.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48544\n",
            "INFO:tensorflow:examples/sec: 702.136\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20901074, step = 21608 (18.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50378\n",
            "INFO:tensorflow:examples/sec: 704.484\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1767845, step = 21708 (18.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49815\n",
            "INFO:tensorflow:examples/sec: 703.763\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16660574, step = 21808 (18.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49773\n",
            "INFO:tensorflow:examples/sec: 703.709\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18873018, step = 21908 (18.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48408\n",
            "INFO:tensorflow:examples/sec: 701.962\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18533434, step = 22008 (19.365 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.16373\n",
            "INFO:tensorflow:examples/sec: 660.957\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.23157617, step = 22108 (18.215 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49016\n",
            "INFO:tensorflow:examples/sec: 702.74\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.22146288, step = 22208 (18.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49076\n",
            "INFO:tensorflow:examples/sec: 702.817\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19383717, step = 22308 (18.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50062\n",
            "INFO:tensorflow:examples/sec: 704.079\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.15467443, step = 22408 (18.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4961\n",
            "INFO:tensorflow:examples/sec: 703.501\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20101225, step = 22508 (18.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49107\n",
            "INFO:tensorflow:examples/sec: 702.857\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.13229083, step = 22608 (19.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.19402\n",
            "INFO:tensorflow:examples/sec: 664.835\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1826052, step = 22708 (18.234 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48427\n",
            "INFO:tensorflow:examples/sec: 701.987\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16932796, step = 22808 (18.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49494\n",
            "INFO:tensorflow:examples/sec: 703.352\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17720748, step = 22908 (18.335 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.45413\n",
            "INFO:tensorflow:examples/sec: 698.128\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21378101, step = 23008 (18.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50767\n",
            "INFO:tensorflow:examples/sec: 704.982\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18923253, step = 23108 (18.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48839\n",
            "INFO:tensorflow:examples/sec: 702.514\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.14754978, step = 23208 (18.225 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48703\n",
            "INFO:tensorflow:examples/sec: 702.34\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17715456, step = 23308 (18.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49434\n",
            "INFO:tensorflow:examples/sec: 703.276\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.22052681, step = 23408 (19.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.22592\n",
            "INFO:tensorflow:examples/sec: 668.918\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17914099, step = 23508 (18.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49019\n",
            "INFO:tensorflow:examples/sec: 702.745\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17821327, step = 23608 (18.247 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48039\n",
            "INFO:tensorflow:examples/sec: 701.49\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20113781, step = 23708 (18.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48325\n",
            "INFO:tensorflow:examples/sec: 701.856\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18766877, step = 23808 (18.238 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48284\n",
            "INFO:tensorflow:examples/sec: 701.803\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17318475, step = 23908 (18.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4848\n",
            "INFO:tensorflow:examples/sec: 702.054\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17984049, step = 24008 (18.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49797\n",
            "INFO:tensorflow:examples/sec: 703.741\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19008663, step = 24108 (19.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.21443\n",
            "INFO:tensorflow:examples/sec: 667.447\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17658234, step = 24208 (18.229 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48522\n",
            "INFO:tensorflow:examples/sec: 702.108\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16760473, step = 24308 (18.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49252\n",
            "INFO:tensorflow:examples/sec: 703.043\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17982703, step = 24408 (18.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47282\n",
            "INFO:tensorflow:examples/sec: 700.521\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17493542, step = 24508 (18.338 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.45391\n",
            "INFO:tensorflow:examples/sec: 698.101\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1614497, step = 24608 (18.309 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46171\n",
            "INFO:tensorflow:examples/sec: 699.099\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 24708 into gs://human-protein-atlas-kaggle/output-noaux/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.19406018, step = 24708 (29.750 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.36077\n",
            "INFO:tensorflow:examples/sec: 430.178\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21560942, step = 24808 (18.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49737\n",
            "INFO:tensorflow:examples/sec: 703.664\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1863822, step = 24908 (18.230 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4853\n",
            "INFO:tensorflow:examples/sec: 702.119\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16813113, step = 25008 (18.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49415\n",
            "INFO:tensorflow:examples/sec: 703.252\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.22438139, step = 25108 (18.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49456\n",
            "INFO:tensorflow:examples/sec: 703.304\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17011584, step = 25208 (18.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50003\n",
            "INFO:tensorflow:examples/sec: 704.004\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19604214, step = 25308 (18.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49757\n",
            "INFO:tensorflow:examples/sec: 703.689\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18387803, step = 25408 (18.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4999\n",
            "INFO:tensorflow:examples/sec: 703.987\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16401868, step = 25508 (19.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.23488\n",
            "INFO:tensorflow:examples/sec: 670.065\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19722064, step = 25608 (18.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49986\n",
            "INFO:tensorflow:examples/sec: 703.982\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20145349, step = 25708 (18.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49438\n",
            "INFO:tensorflow:examples/sec: 703.281\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18242705, step = 25808 (18.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47986\n",
            "INFO:tensorflow:examples/sec: 701.422\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2233743, step = 25908 (18.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50511\n",
            "INFO:tensorflow:examples/sec: 704.654\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1824589, step = 26008 (18.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47464\n",
            "INFO:tensorflow:examples/sec: 700.753\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16566324, step = 26108 (18.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50747\n",
            "INFO:tensorflow:examples/sec: 704.956\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1789453, step = 26208 (19.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.18851\n",
            "INFO:tensorflow:examples/sec: 664.13\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.15337159, step = 26308 (18.497 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.40642\n",
            "INFO:tensorflow:examples/sec: 692.022\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16509204, step = 26408 (18.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49704\n",
            "INFO:tensorflow:examples/sec: 703.621\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1660966, step = 26508 (18.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4696\n",
            "INFO:tensorflow:examples/sec: 700.109\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19026583, step = 26608 (18.337 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.45347\n",
            "INFO:tensorflow:examples/sec: 698.044\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17533174, step = 26708 (18.342 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.45164\n",
            "INFO:tensorflow:examples/sec: 697.81\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18250178, step = 26808 (19.442 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.14248\n",
            "INFO:tensorflow:examples/sec: 658.238\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18259473, step = 26908 (18.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48909\n",
            "INFO:tensorflow:examples/sec: 702.604\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19598664, step = 27008 (18.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49224\n",
            "INFO:tensorflow:examples/sec: 703.007\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16384956, step = 27108 (18.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49946\n",
            "INFO:tensorflow:examples/sec: 703.931\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19236498, step = 27208 (18.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49458\n",
            "INFO:tensorflow:examples/sec: 703.307\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17806916, step = 27308 (18.218 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48818\n",
            "INFO:tensorflow:examples/sec: 702.487\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17478935, step = 27408 (18.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50679\n",
            "INFO:tensorflow:examples/sec: 704.869\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17652948, step = 27508 (18.213 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49043\n",
            "INFO:tensorflow:examples/sec: 702.775\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.22334878, step = 27608 (19.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.22557\n",
            "INFO:tensorflow:examples/sec: 668.873\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17166996, step = 27708 (18.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46286\n",
            "INFO:tensorflow:examples/sec: 699.247\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1801974, step = 27808 (18.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46922\n",
            "INFO:tensorflow:examples/sec: 700.06\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16152793, step = 27908 (18.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46912\n",
            "INFO:tensorflow:examples/sec: 700.048\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16184528, step = 28008 (18.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46492\n",
            "INFO:tensorflow:examples/sec: 699.51\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16933392, step = 28108 (18.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49051\n",
            "INFO:tensorflow:examples/sec: 702.785\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.22431624, step = 28208 (18.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49095\n",
            "INFO:tensorflow:examples/sec: 702.841\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19300507, step = 28308 (19.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.16805\n",
            "INFO:tensorflow:examples/sec: 661.511\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16371047, step = 28408 (18.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49678\n",
            "INFO:tensorflow:examples/sec: 703.588\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1876586, step = 28508 (18.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48937\n",
            "INFO:tensorflow:examples/sec: 702.639\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16342323, step = 28608 (18.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48837\n",
            "INFO:tensorflow:examples/sec: 702.511\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16636348, step = 28708 (18.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49233\n",
            "INFO:tensorflow:examples/sec: 703.019\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.15896747, step = 28808 (18.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50214\n",
            "INFO:tensorflow:examples/sec: 704.274\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16962837, step = 28908 (19.483 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.13261\n",
            "INFO:tensorflow:examples/sec: 656.974\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21535333, step = 29008 (18.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.511\n",
            "INFO:tensorflow:examples/sec: 705.408\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.15603831, step = 29108 (18.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47565\n",
            "INFO:tensorflow:examples/sec: 700.883\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17145838, step = 29208 (18.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50425\n",
            "INFO:tensorflow:examples/sec: 704.544\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18845227, step = 29308 (18.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46221\n",
            "INFO:tensorflow:examples/sec: 699.163\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19427358, step = 29408 (18.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.51614\n",
            "INFO:tensorflow:examples/sec: 706.065\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17761546, step = 29508 (18.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.44547\n",
            "INFO:tensorflow:examples/sec: 697.02\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.21131526, step = 29608 (18.817 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.31449\n",
            "INFO:tensorflow:examples/sec: 680.254\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1626094, step = 29708 (19.231 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.19878\n",
            "INFO:tensorflow:examples/sec: 665.444\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17458199, step = 29808 (18.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47044\n",
            "INFO:tensorflow:examples/sec: 700.217\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19059683, step = 29908 (18.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.461\n",
            "INFO:tensorflow:examples/sec: 699.008\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.15255141, step = 30008 (18.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.46797\n",
            "INFO:tensorflow:examples/sec: 699.9\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 30108 into gs://human-protein-atlas-kaggle/output-noaux/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.16483653, step = 30108 (28.772 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.47595\n",
            "INFO:tensorflow:examples/sec: 444.922\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18900533, step = 30208 (18.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49573\n",
            "INFO:tensorflow:examples/sec: 703.453\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20602594, step = 30308 (19.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.192\n",
            "INFO:tensorflow:examples/sec: 664.576\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19779044, step = 30408 (18.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49749\n",
            "INFO:tensorflow:examples/sec: 703.679\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19875352, step = 30508 (18.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50419\n",
            "INFO:tensorflow:examples/sec: 704.536\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17439023, step = 30608 (18.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50545\n",
            "INFO:tensorflow:examples/sec: 704.698\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.23021632, step = 30708 (18.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49146\n",
            "INFO:tensorflow:examples/sec: 702.907\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2036656, step = 30808 (18.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4935\n",
            "INFO:tensorflow:examples/sec: 703.168\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16808066, step = 30908 (18.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48812\n",
            "INFO:tensorflow:examples/sec: 702.479\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19399057, step = 31008 (19.341 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.17025\n",
            "INFO:tensorflow:examples/sec: 661.791\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.20208815, step = 31108 (18.236 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48376\n",
            "INFO:tensorflow:examples/sec: 701.921\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1786713, step = 31208 (18.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48294\n",
            "INFO:tensorflow:examples/sec: 701.816\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17961806, step = 31308 (18.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47721\n",
            "INFO:tensorflow:examples/sec: 701.083\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.19546825, step = 31408 (18.233 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48597\n",
            "INFO:tensorflow:examples/sec: 702.204\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.18263523, step = 31508 (18.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.47664\n",
            "INFO:tensorflow:examples/sec: 701.01\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17568915, step = 31608 (19.434 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.14565\n",
            "INFO:tensorflow:examples/sec: 658.644\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.17352161, step = 31708 (18.220 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.48855\n",
            "INFO:tensorflow:examples/sec: 702.535\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.15415081, step = 31808 (18.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49282\n",
            "INFO:tensorflow:examples/sec: 703.081\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.15871666, step = 31908 (18.222 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.4881\n",
            "INFO:tensorflow:examples/sec: 702.476\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16645804, step = 32008 (18.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.50212\n",
            "INFO:tensorflow:examples/sec: 704.272\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.16554305, step = 32108 (18.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49958\n",
            "INFO:tensorflow:examples/sec: 703.947\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.2006489, step = 32208 (18.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.49439\n",
            "INFO:tensorflow:examples/sec: 703.282\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.15382788, step = 32308 (18.140 sec)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TYN3etXr2NRM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "do_it('eval')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NgCutQhuc1B9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "do_it('predict')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KveM9YMbKeWi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
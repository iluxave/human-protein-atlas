{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TPUInceptionV3+RNN-TF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "najlB4tnapzz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install imgaug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h4wTFMNrAZY6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/competitions/human-protein-atlas-image-classification/output\n",
        "import os\n",
        "os.chdir('/content/competitions/human-protein-atlas-image-classification')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RVBQEkhE1wFO",
        "colab_type": "code",
        "outputId": "ec96cc9a-489e-4f74-9c27-93910b7393c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.110.132.194:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 5430434907095332708),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14767560081273852568),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 11834093469595998535),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4328427905541093280),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 17340163491948052446),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4312709332169993133),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 860592450322314050),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 74513726444831943),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 3445617430047872947),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 1856635537024405041),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 8184955560853351095),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 18376990445723569978)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a5OO_GRS5PdZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.io\n",
        "from skimage.transform import resize\n",
        "#from imgaug import augmenters as iaa\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.utils import class_weight, shuffle\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "SIZE = 299\n",
        "SEED = 777\n",
        "THRESHOLD = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TopFylv55Pde",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UAu2PQ_PD_fX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GCS access helpers ##\n",
        "Courtesy of https://stackoverflow.com/a/52106361/7724174\n",
        "\n",
        "These functions let us get data from GCS into our notebook."
      ]
    },
    {
      "metadata": {
        "id": "bDZlL-_K5Pdg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Load dataset info\n",
        "#DIR = '../input/'\n",
        "#DIR='gs://human-protein-atlas-kaggle/'\n",
        "#data = dd.read_csv(DIR+'train.csv')\n",
        "#data = data.compute()\n",
        "\n",
        "DATA_DIR='gs://human-protein-atlas-kaggle/'\n",
        "\n",
        "from tensorflow.python.lib.io import file_io\n",
        "with file_io.FileIO(DATA_DIR+'train.csv', 'r') as f:\n",
        "    data = pd.read_csv(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KRMpE3B95Pdr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SHAPE = (299, 299, 3)\n",
        "NUM_CLASSES=28\n",
        "#epochs = 400;\n",
        "epochs = 30\n",
        "#batch_size = 256;\n",
        "VAL_RATIO = .1;\n",
        "DEBUG = False\n",
        "channels = [\"green\", \"blue\", \"red\"]\n",
        "lstmUnits=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ciXtnu0dfPO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data input pipline ##\n",
        "This isn't fully optimized yet, but it's good enough."
      ]
    },
    {
      "metadata": {
        "id": "kAm-HbRHN-U3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TF_DIR=DATA_DIR+'train'\n",
        "DS_DIMS=[512,512]\n",
        "NN_DIMS=[299,299]\n",
        "REC_BUF_SIZE=453762 # This is approximate size for 512x512 images\n",
        "NUM_PARALLEL_CALLS=8 # number of cores in the system\n",
        "class HPADataset:\n",
        "    def __init__(self, shards, aug=True, input_path=TF_DIR):\n",
        "        self.shards = shards\n",
        "        self.aug = aug\n",
        "        self.input_path = input_path\n",
        "    def input_fn(self, params):\n",
        "        if 'batch_size' in params:\n",
        "            batch_size=params['batch_size']\n",
        "        else:\n",
        "            batch_size=32\n",
        "        def _parse_function(example_proto):\n",
        "            features = {}\n",
        "            for c in channels:\n",
        "                features[\"image/%s/filename\"%c] = tf.FixedLenFeature((), tf.string, default_value=\"\")\n",
        "                features[\"image/%s/encoded\"%c] = tf.FixedLenFeature((), tf.string, default_value=\"\")\n",
        "            features[\"image/label\"] = tf.FixedLenFeature((NUM_CLASSES), tf.float32, default_value=[0]*NUM_CLASSES)\n",
        "            features[\"image/id\"]=tf.FixedLenFeature((), tf.string, default_value='')\n",
        "            #features[\"image/id\"]=tf.FixedLenFeature((1024), tf.int8, default_value=0)\n",
        "            parsed_features = tf.parse_single_example(example_proto, features)\n",
        "            imgs=[]\n",
        "            for c in channels:\n",
        "                img=parsed_features['image/%s/encoded'%c]\n",
        "                #print(img)\n",
        "                img=tf.image.decode_png(img, channels=1)\n",
        "                shape=tf.shape(img)\n",
        "                #shape_print=tf.print(shape)\n",
        "                img=tf.reshape(img, DS_DIMS)\n",
        "                imgs.append(img)\n",
        "            image=tf.stack(imgs, axis=-1, name='combine_channels')\n",
        "            image=tf.image.resize_images(image, NN_DIMS)\n",
        "            # For simplicity, we'll use imgaug with py_op here\n",
        "            def augment(image):\n",
        "                augment_img = iaa.Sequential([\n",
        "                    iaa.OneOf([\n",
        "                        iaa.Affine(rotate=0),\n",
        "                        iaa.Affine(rotate=90),\n",
        "                        iaa.Affine(rotate=180),\n",
        "                        iaa.Affine(rotate=270),\n",
        "                        iaa.Fliplr(0.5),\n",
        "                        iaa.Flipud(0.5),\n",
        "                    ])], random_order=True)\n",
        "\n",
        "                image_aug = augment_img.augment_image(image)\n",
        "                return image_aug\n",
        "            if self.aug:\n",
        "                image=tf.py_func(augment, [image], tf.float32, name='augment')\n",
        "                image=tf.reshape(image, NN_DIMS+[len(channels)])\n",
        "            image=tf.cast(image, tf.float32)\n",
        "            image=image / 255.\n",
        "            \n",
        "            ids=parsed_features['image/id']\n",
        "            return image, ids, parsed_features[\"image/label\"]\n",
        "\n",
        "        def parse_ids(image, ids, labels):\n",
        "            print(ids)\n",
        "            ids=tf.strings.split(ids, '-')\n",
        "            print(ids)\n",
        "            ids=tf.sparse.to_dense(ids, default_value='')\n",
        "            print(ids)\n",
        "            ids=tf.strings.to_number(ids, tf.int32)\n",
        "            print(ids)\n",
        "            ids=tf.reshape(ids, (-1, 5))\n",
        "            print(ids)\n",
        "            return image, ids, labels\n",
        "\n",
        "        fnames=['{dir}/hpa_{w}x{h}_{num}.tfrecords'.format(dir=self.input_path, w=DS_DIMS[0], h=DS_DIMS[1], num=shard) for shard in self.shards]\n",
        "        dataset=tf.data.TFRecordDataset(fnames,\n",
        "                                        buffer_size=REC_BUF_SIZE*2*len(self.shards),\n",
        "                                        num_parallel_reads=len(self.shards))\n",
        "        dataset=dataset.map(_parse_function, num_parallel_calls=NUM_PARALLEL_CALLS)\n",
        "        if params['mode']!='predict':\n",
        "            dataset=dataset.shuffle(1000)\n",
        "        dataset=dataset.prefetch(batch_size*8)\n",
        "        dataset=dataset.batch(batch_size, drop_remainder=False)\n",
        "        dataset=dataset.map(parse_ids, num_parallel_calls=NUM_PARALLEL_CALLS)\n",
        "        if params['mode']=='predict':\n",
        "            def pad_batch(img, ids, labels):\n",
        "                def pd(x):\n",
        "                    paddings = [\n",
        "                        [0, batch_size-tf.shape(img)[0]],\n",
        "                    ]\n",
        "                    for i in range(1,len(x.shape)):\n",
        "                        paddings.append([0, 0])\n",
        "                    pad = tf.pad(x, paddings)\n",
        "                    shape = pad.shape.as_list()\n",
        "                    shape[0] = batch_size\n",
        "                    return tf.reshape(pad, shape)\n",
        "                return {'image':pd(img), 'ids':pd(ids)}, pd(labels)\n",
        "                #return pd(img), pd(ids), pd(labels)\n",
        "            dataset=dataset.map(pad_batch)\n",
        "        dataset=dataset.prefetch(2)\n",
        "        if params['mode']=='predict':\n",
        "            print(dataset)\n",
        "            return dataset\n",
        "        dataset=dataset.repeat()\n",
        "        img, ids, labels = dataset.make_one_shot_iterator().get_next()\n",
        "        return {'image':img, 'ids':ids}, labels\n",
        "#with tf.Graph().as_default():\n",
        "#    test=HPADataset([1,2], False).input_fn({\n",
        "#        'mode':'predict',\n",
        "#        'batch_size': 1024\n",
        "#    })\n",
        "#    with tf.Session() as sess:\n",
        "#        sess.run(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_VNMbwOsvV-4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tg = HPADataset(range(8), False)\n",
        "vg = HPADataset([8, 9], False)\n",
        "test=HPADataset(range(10), False, input_path=DATA_DIR+'test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JoxbV4Hsd1jA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model ##\n",
        "\n",
        "What follows is our model based on pure tensorflow and the inception model present there. Large portions of this code are lifted from https://github.com/tensorflow/tpu/blob/master/models/experimental/inception/inception_v3.py\n"
      ]
    },
    {
      "metadata": {
        "id": "kD7NGt2Y5Pdz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.contrib import summary\n",
        "from tensorflow.contrib.framework.python.ops import arg_scope\n",
        "from tensorflow.contrib.slim.nets import inception\n",
        "from tensorflow.contrib.training.python.training import evaluation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k3QEuM7qf4rp",
        "colab_type": "code",
        "outputId": "490d8416-0e67-4d0e-f15f-1e5fc47a1c96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "cell_type": "code",
      "source": [
        "### Some model settings\n",
        "precision='float32'\n",
        "log_device_placement=False\n",
        "clear_update_collections=True\n",
        "num_classes=NUM_CLASSES\n",
        "display_tensors=True\n",
        "use_tpu=True\n",
        "#train_batch_size=1024\n",
        "#geval_batch_size=1024\n",
        "train_batch_size=512\n",
        "geval_batch_size=512\n",
        "glearning_rate=0.165\n",
        "learning_rate_decay=0.94\n",
        "use_learning_rate_warmup=False\n",
        "warmup_epochs=7\n",
        "cold_epochs=2\n",
        "learning_rate_decay_epochs=6\n",
        "skip_host_call=True\n",
        "goptimizer='RMS'\n",
        "moving_average=True\n",
        "MOVING_AVERAGE_DECAY = 0.995\n",
        "# Batchnorm moving mean/variance parameters\n",
        "BATCH_NORM_DECAY = 0.996\n",
        "BATCH_NORM_EPSILON = 1e-3\n",
        "\n",
        "WEIGHT_DECAY = 0.00004\n",
        "RMSPROP_DECAY = 0.9                # Decay term for RMSProp.\n",
        "RMSPROP_MOMENTUM = 0.9             # Momentum in RMSProp.\n",
        "RMSPROP_EPSILON = 1.0              # Epsilon term for RMSProp.\n",
        "\n",
        "min_depth=16\n",
        "transpose_enabled=False\n",
        "spatial_squeeze=True\n",
        "\n",
        "_NUM_TRAIN_IMAGES = 24858\n",
        "_NUM_EVAL_IMAGES = 6214\n",
        "epochs=30\n",
        "ITERATIONS=_NUM_TRAIN_IMAGES*epochs/train_batch_size\n",
        "num_shards=8 # 8 in original..\n",
        "#model_dir='/content/competitions/human-protein-atlas-image-classification/output'\n",
        "model_dir=DATA_DIR+'output/'\n",
        "save_checkpoints_secs=1000\n",
        "save_summary_steps=100\n",
        "eval_timeout=None\n",
        "train_steps_per_eval=int(_NUM_TRAIN_IMAGES/train_batch_size) # essentially one epoch\n",
        "\n",
        "dropout_keep_prob=0.8\n",
        "train_steps=int(ITERATIONS)\n",
        "print('Will train for {train} steps'.format(train=train_steps))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Will train for 1456 steps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9NYAVMEH45rM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def tensor_transform_fn(data, perm):\n",
        "  \"\"\"Transpose function.\n",
        "\n",
        "  This function is used to transpose an image tensor on the host and then\n",
        "  perform an inverse transpose on the TPU. The transpose on the TPU gets\n",
        "  effectively elided thus voiding any associated computational cost.\n",
        "\n",
        "  NOTE: Eventually the compiler will be able to detect when this kind of\n",
        "  operation may prove beneficial and perform these types of transformations\n",
        "  implicitly, voiding the need for user intervention\n",
        "\n",
        "  Args:\n",
        "    data: Tensor to be transposed\n",
        "    perm: New ordering of dimensions\n",
        "\n",
        "  Returns:\n",
        "    Transposed tensor\n",
        "  \"\"\"\n",
        "  if transpose_enabled:\n",
        "    return tf.transpose(data, perm)\n",
        "  return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Up9dhjFpe-14",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib import layers\n",
        "from tensorflow.contrib.layers.python.layers import layers as layers_lib\n",
        "from tensorflow.python.ops import array_ops\n",
        "\n",
        "def inception_model_fn(features, labels, mode, params):\n",
        "    \"\"\"Inception v3 model using Estimator API.\"\"\"\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "    is_eval = (mode == tf.estimator.ModeKeys.EVAL)\n",
        "\n",
        "    print(features)\n",
        "    print(labels)\n",
        "    print(mode)\n",
        "    print(params)\n",
        "    if isinstance(features, dict):\n",
        "        ids = features['ids']\n",
        "        features = features['image']\n",
        "    else:\n",
        "        print(\"Features should be a dictionary with 'image' and 'id' keys\")\n",
        "        raise ValueError('invalid input')\n",
        "\n",
        "    features = tensor_transform_fn(features, params['input_perm'])\n",
        "\n",
        "    # This nested function allows us to avoid duplicating the logic which\n",
        "    # builds the network, for different values of --precision.\n",
        "    def build_inception_v3(final_endpoint='Mixed_7c', scope=None):\n",
        "        with tf.variable_scope(\n",
        "            scope, 'InceptionV3', [features, num_classes], reuse=None) as scope:\n",
        "            with arg_scope(\n",
        "              [layers_lib.batch_norm, layers_lib.dropout], is_training=is_training):\n",
        "              net, end_points = inception.inception_v3_base(\n",
        "                  features,\n",
        "                  final_endpoint=final_endpoint\n",
        "              )\n",
        "\n",
        "              # Build our RNNs\n",
        "              def build_rnn(endpoint):\n",
        "                # 1. Unroll our logits horisonatlly and vertically\n",
        "                #print(\"Input endpoint\", endpoint)\n",
        "                shape=endpoint.shape.as_list()\n",
        "                shape=(shape[0], shape[1]*shape[2], shape[3])\n",
        "                #print(\"target shape\", shape)\n",
        "                input_width=tf.reshape(endpoint, shape)\n",
        "                input_height=tf.transpose(endpoint, (0, 2, 1, 3))\n",
        "                input_height=tf.reshape(input_height, shape)\n",
        "                #print(\"Input\", input_height)\n",
        "                lstmCellW = tf.contrib.rnn.LSTMCell(num_units=lstmUnits, use_peepholes=True)\n",
        "                lstmCellH = tf.contrib.rnn.LSTMCell(num_units=lstmUnits, use_peepholes=True)\n",
        "                wouts, wstate=tf.nn.dynamic_rnn(lstmCellW, input_width, scope='width', dtype=tf.float32, parallel_iterations=1024)\n",
        "                houts, hstate=tf.nn.dynamic_rnn(lstmCellH, input_height, scope='height', dtype=tf.float32, parallel_iterations=1024)\n",
        "                #print(\"RNN outs\", wouts, houts)\n",
        "                #print(\"Last of wouts\", wouts[-1])\n",
        "                #wouts=tf.unstack(wouts, axis=1)\n",
        "                #houts=tf.unstack(houts, axis=1)\n",
        "                #print(\"Unstacked\", wouts)\n",
        "                #print(\"Last?\", wouts[-1])\n",
        "                #wouts=wouts[-1]\n",
        "                #houts=houts[-1]\n",
        "                #logits=tf.concat([houts, wouts], name='Logits', axis=-1)\n",
        "                #print(houts, wouts, logits)\n",
        "                logits=tf.concat([wstate.c, hstate.c], name='Logits', axis=-1)\n",
        "                return logits\n",
        "              rnn_logits=[]\n",
        "              #attachements=['Mixed_7b', 'Mixed_7a', 'Mixed_6e']\n",
        "              attachements=['Mixed_7b', 'Mixed_7a']\n",
        "              #attachements=['Mixed_7a']\n",
        "              #attachements=[]\n",
        "              for att_pt in attachements:\n",
        "                    with tf.variable_scope(att_pt+'_rnn'):\n",
        "                        rnn_logits.append(build_rnn(end_points[att_pt]))\n",
        "              #print(rnn_logits)\n",
        "              rnn_logits=tf.concat(rnn_logits, name='FinalRNNLogits', axis=-1)\n",
        "\n",
        "              depth = lambda d: max(d, min_depth)\n",
        "              if 'Mixed_6e' in end_points:\n",
        "                  # Auxiliary Head logits\n",
        "                  with arg_scope(\n",
        "                      [layers.conv2d, layers_lib.max_pool2d, layers_lib.avg_pool2d],\n",
        "                      stride=1,\n",
        "                      padding='SAME'):\n",
        "                    aux_logits = end_points['Mixed_6e']\n",
        "                    with tf.variable_scope('AuxLogits'):\n",
        "                      aux_logits = layers_lib.avg_pool2d(\n",
        "                          aux_logits, [5, 5],\n",
        "                          stride=3,\n",
        "                          padding='VALID',\n",
        "                          scope='AvgPool_1a_5x5')\n",
        "                      aux_logits = layers.conv2d(\n",
        "                          aux_logits, depth(128), [1, 1], scope='Conv2d_1b_1x1')\n",
        "\n",
        "                      # Shape of feature map before the final layer.\n",
        "                      kernel_size = [5, 5]\n",
        "                      aux_logits = layers.conv2d(\n",
        "                          aux_logits,\n",
        "                          depth(768),\n",
        "                          kernel_size,\n",
        "                          weights_initializer=tf.initializers.truncated_normal(stddev=0.01),\n",
        "                          padding='VALID',\n",
        "                          scope='Conv2d_2a_{}x{}'.format(*kernel_size))\n",
        "                      aux_logits = layers.conv2d(\n",
        "                          aux_logits,\n",
        "                          num_classes, [1, 1],\n",
        "                          activation_fn=None,\n",
        "                          normalizer_fn=None,\n",
        "                          weights_initializer=tf.initializers.truncated_normal(stddev=0.001),\n",
        "                          scope='Conv2d_2b_1x1')\n",
        "                      if spatial_squeeze:\n",
        "                        aux_logits = array_ops.squeeze(\n",
        "                            aux_logits, name='SpatialSqueeze')\n",
        "                      end_points['AuxLogits'] = aux_logits\n",
        "            # Final pooling and prediction\n",
        "            with tf.variable_scope('Logits'):\n",
        "                #kernel_size = [8,8]\n",
        "                #net = layers_lib.avg_pool2d(net, kernel_size, padding='VALID', scope='AvgPool_1a{}x{}'.format(*kernel_size))\n",
        "                ## 1x1x2048\n",
        "                #net = layers_lib.dropout(net, keep_prob=dropout_keep_prob, scope='Dropout_1b')\n",
        "                #end_points['PreLogits']=net\n",
        "                ##2048\n",
        "                #logits = layers.conv2d(net, num_classes, [1,1], activation_fn=None, normalizer_fn=None, scope='Conv2d_1c_1x1')\n",
        "                #if spatial_squeeze:\n",
        "                #    logits = array_ops.squeeze(logits, [1,2], name='SpatialSqueeze')\n",
        "                #end_points['Logits']=logits\n",
        "                #end_points['Predictions']=tf.nn.sigmoid(logits, name='Predicitons')\n",
        "                #return logits, end_points\n",
        "\n",
        "                net = rnn_logits\n",
        "                end_points['PreLogits']=net\n",
        "                end_points['rnn_logits']=net\n",
        "                net = layers_lib.dropout(net, keep_prob=dropout_keep_prob, scope='Dropout_1b')\n",
        "                print(net)\n",
        "                net = tf.expand_dims(net, 1)\n",
        "                net = tf.expand_dims(net, 1)\n",
        "                print(net)\n",
        "                logits = layers.conv2d(net, num_classes, 1, activation_fn=None, normalizer_fn=None, scope='Conv2d_1c_1x1')\n",
        "                if spatial_squeeze:\n",
        "                    logits = array_ops.squeeze(logits, [1,2], name='SpatialSqueeze')\n",
        "                # 28\n",
        "                end_points['Logits']=logits\n",
        "                end_points['Predictions'] = tf.nn.sigmoid(logits, name='Predictions')\n",
        "                return logits, end_points\n",
        "\n",
        "    def build_network(precision):\n",
        "        if precision == 'bfloat16':\n",
        "            with tf.contrib.tpu.bfloat16_scope():\n",
        "                logits, end_points = build_inception_v3()\n",
        "            logits = tf.cast(logits, tf.float32)\n",
        "        elif precision == 'float32':\n",
        "            logits, end_points = build_inception_v3()\n",
        "        return logits, end_points\n",
        "\n",
        "    if clear_update_collections:\n",
        "        # updates_collections must be set to None in order to use fused batchnorm\n",
        "        with arg_scope(inception.inception_v3_arg_scope(\n",
        "            weight_decay=0.0,\n",
        "            batch_norm_decay=BATCH_NORM_DECAY,\n",
        "            batch_norm_epsilon=BATCH_NORM_EPSILON,\n",
        "            updates_collections=None)):\n",
        "            logits, end_points = build_network('float32')\n",
        "    else:\n",
        "        with arg_scope(inception.inception_v3_arg_scope(\n",
        "            batch_norm_decay=BATCH_NORM_DECAY,\n",
        "            batch_norm_epsilon=BATCH_NORM_EPSILON)):\n",
        "            logits, end_points = build_network('float32')\n",
        "\n",
        "    predictions = {\n",
        "        'logits': logits,\n",
        "        'classes': tf.math.greater(logits, 0.2),\n",
        "        'probabilities': end_points['Predictions'],\n",
        "        'predictions': end_points['Predictions'],\n",
        "        'ids': ids,\n",
        "        #'rnn_logits': end_points['rnn_logits'],\n",
        "        #'dropout': end_points['dropout'],\n",
        "    }\n",
        "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
        "        predictions['labels'] = labels\n",
        "    print(predictions)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.contrib.tpu.TPUEstimatorSpec(\n",
        "            mode=mode,\n",
        "            predictions=predictions,\n",
        "            export_outputs={\n",
        "                'classify': tf.estimator.export.PredictOutput(predictions)\n",
        "            })\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.EVAL and display_tensors and (\n",
        "        not use_tpu):\n",
        "        with tf.control_dependencies([\n",
        "            tf.Print(\n",
        "                predictions['classes'], [predictions['classes']],\n",
        "                summarize=geval_batch_size,\n",
        "                message='prediction: ')\n",
        "        ]):\n",
        "            labels = tf.Print(\n",
        "                labels, [labels], summarize=geval_batch_size, message='label: ')\n",
        "\n",
        "    # in our case labels come pre-encoded\n",
        "    one_hot_labels = labels #tf.one_hot(labels, num_classes, dtype=tf.int32)\n",
        "\n",
        "    if 'AuxLogits' in end_points:\n",
        "        tf.losses.sigmoid_cross_entropy(\n",
        "            multi_class_labels=one_hot_labels,\n",
        "            logits=tf.cast(end_points['AuxLogits'], tf.float32),\n",
        "            weights=0.4,\n",
        "            label_smoothing=0.1,\n",
        "            scope='aux_loss')\n",
        "\n",
        "    tf.losses.sigmoid_cross_entropy(\n",
        "        multi_class_labels=one_hot_labels,\n",
        "        logits=logits,\n",
        "        #weights=1.0,\n",
        "        #label_smoothing=0.1,\n",
        "        reduction=tf.losses.Reduction.MEAN\n",
        "    )\n",
        "\n",
        "    losses = tf.add_n(tf.losses.get_losses())\n",
        "    l2_loss = []\n",
        "    for v in tf.trainable_variables():\n",
        "        if 'BatchNorm' not in v.name and 'weights' in v.name:\n",
        "            l2_loss.append(tf.nn.l2_loss(v))\n",
        "    loss = losses + WEIGHT_DECAY * tf.add_n(l2_loss)\n",
        "\n",
        "    initial_learning_rate = glearning_rate * train_batch_size / 256\n",
        "    if use_learning_rate_warmup:\n",
        "        # Adjust initial learning rate to match final warmup rate\n",
        "        warmup_decay = learning_rate_decay**(\n",
        "            (warmup_epochs + cold_epochs) /\n",
        "            learning_rate_decay_epochs)\n",
        "        adj_initial_learning_rate = initial_learning_rate * warmup_decay\n",
        "\n",
        "    final_learning_rate = 0.0001 * initial_learning_rate\n",
        "\n",
        "    host_call = None\n",
        "    train_op = None\n",
        "  \n",
        "    if is_training:\n",
        "        batches_per_epoch = _NUM_TRAIN_IMAGES / train_batch_size\n",
        "        global_step = tf.train.get_or_create_global_step()\n",
        "        current_epoch = tf.cast(\n",
        "            (tf.cast(global_step, tf.float32) / batches_per_epoch), tf.int32)\n",
        "\n",
        "        learning_rate = tf.train.exponential_decay(\n",
        "            learning_rate=initial_learning_rate,\n",
        "            global_step=global_step,\n",
        "            decay_steps=int(learning_rate_decay_epochs * batches_per_epoch),\n",
        "            decay_rate=learning_rate_decay,\n",
        "            staircase=True)\n",
        "\n",
        "        if use_learning_rate_warmup:\n",
        "            wlr = 0.1 * adj_initial_learning_rate\n",
        "            wlr_height = tf.cast(\n",
        "                0.9 * adj_initial_learning_rate /\n",
        "                (warmup_epochs + learning_rate_decay_epochs - 1),\n",
        "                tf.float32)\n",
        "            epoch_offset = tf.cast(cold_epochs - 1, tf.int32)\n",
        "            exp_decay_start = (warmup_epochs + cold_epochs +\n",
        "                             learning_rate_decay_epochs)\n",
        "            lin_inc_lr = tf.add(\n",
        "                wlr, tf.multiply(\n",
        "                    tf.cast(tf.subtract(current_epoch, epoch_offset), tf.float32),\n",
        "                    wlr_height))\n",
        "            learning_rate = tf.where(\n",
        "                tf.greater_equal(current_epoch, cold_epochs),\n",
        "                (tf.where(tf.greater_equal(current_epoch, exp_decay_start),\n",
        "                          learning_rate, lin_inc_lr)),\n",
        "                wlr)\n",
        "\n",
        "        # Set a minimum boundary for the learning rate.\n",
        "        learning_rate = tf.maximum(\n",
        "            learning_rate, final_learning_rate, name='learning_rate')\n",
        "\n",
        "        if goptimizer == 'sgd':\n",
        "            tf.logging.info('Using SGD optimizer')\n",
        "            optimizer = tf.train.GradientDescentOptimizer(\n",
        "                learning_rate=learning_rate)\n",
        "        elif goptimizer == 'momentum':\n",
        "            tf.logging.info('Using Momentum optimizer')\n",
        "            optimizer = tf.train.MomentumOptimizer(\n",
        "                learning_rate=learning_rate, momentum=0.9)\n",
        "        elif goptimizer == 'RMS':\n",
        "            tf.logging.info('Using RMS optimizer')\n",
        "            optimizer = tf.train.RMSPropOptimizer(\n",
        "                learning_rate,\n",
        "                RMSPROP_DECAY,\n",
        "                momentum=RMSPROP_MOMENTUM,\n",
        "                epsilon=RMSPROP_EPSILON)\n",
        "        else:\n",
        "            tf.logging.fatal('Unknown optimizer:', optimizer)\n",
        "\n",
        "        if use_tpu:\n",
        "            optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
        "\n",
        "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "        if params['warmup']:\n",
        "            trainable_vars = tf.contrib.framework.get_model_variables()\n",
        "            var_list=tf.contrib.framework.filter_variables(trainable_vars, exclude_patterns='.*Mixed_.*_rnn.*')\n",
        "            trainable_vars = tf.contrib.framework.get_trainable_variables()\n",
        "            var_list=tf.contrib.framework.filter_variables(trainable_vars, exclude_patterns=var_list)\n",
        "            print('Training', var_list)\n",
        "        else:\n",
        "            var_list=None\n",
        "        with tf.control_dependencies(update_ops):\n",
        "            train_op = optimizer.minimize(loss, global_step=global_step, var_list=var_list)\n",
        "        if moving_average:\n",
        "            ema = tf.train.ExponentialMovingAverage(\n",
        "                decay=MOVING_AVERAGE_DECAY, num_updates=global_step)\n",
        "            variables_to_average = (\n",
        "                tf.trainable_variables() + tf.moving_average_variables())\n",
        "            with tf.control_dependencies([train_op]), tf.name_scope('moving_average'):\n",
        "                train_op = ema.apply(variables_to_average)\n",
        "\n",
        "        # To log the loss, current learning rate, and epoch for Tensorboard, the\n",
        "        # summary op needs to be run on the host CPU via host_call. host_call\n",
        "        # expects [batch_size, ...] Tensors, thus reshape to introduce a batch\n",
        "        # dimension. These Tensors are implicitly concatenated to\n",
        "        # [params['batch_size']].\n",
        "        gs_t = tf.reshape(global_step, [1])\n",
        "        loss_t = tf.reshape(loss, [1])\n",
        "        lr_t = tf.reshape(learning_rate, [1])\n",
        "        ce_t = tf.reshape(current_epoch, [1])\n",
        "\n",
        "        if not skip_host_call:\n",
        "            def host_call_fn(gs, loss, lr, ce):\n",
        "                \"\"\"Training host call. Creates scalar summaries for training metrics.\n",
        "                This function is executed on the CPU and should not directly reference\n",
        "                any Tensors in the rest of the `model_fn`. To pass Tensors from the\n",
        "                model to the `metric_fn`, provide them as part of the `host_call`. See\n",
        "                https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/TPUEstimatorSpec\n",
        "                for more information.\n",
        "                Arguments should match the list of `Tensor` objects passed as the second\n",
        "                element in the tuple passed to `host_call`.\n",
        "                Args:\n",
        "                  gs: `Tensor with shape `[batch]` for the global_step\n",
        "                  loss: `Tensor` with shape `[batch]` for the training loss.\n",
        "                  lr: `Tensor` with shape `[batch]` for the learning_rate.\n",
        "                  ce: `Tensor` with shape `[batch]` for the current_epoch.\n",
        "                Returns:\n",
        "                  List of summary ops to run on the CPU host.\n",
        "                \"\"\"\n",
        "                gs = gs[0]\n",
        "                with summary.create_file_writer(model_dir).as_default():\n",
        "                    with summary.always_record_summaries():\n",
        "                        summary.scalar('loss', tf.reduce_mean(loss), step=gs)\n",
        "                        summary.scalar('learning_rate', tf.reduce_mean(lr), step=gs)\n",
        "                        summary.scalar('current_epoch', tf.reduce_mean(ce), step=gs)\n",
        "\n",
        "                    return summary.all_summary_ops()\n",
        "\n",
        "            host_call = (host_call_fn, [gs_t, loss_t, lr_t, ce_t])\n",
        "\n",
        "    eval_metrics = None\n",
        "    if is_eval:\n",
        "        def metric_fn(labels, logits):\n",
        "            \"\"\"Evaluation metric function. Evaluates accuracy.\n",
        "            This function is executed on the CPU and should not directly reference\n",
        "            any Tensors in the rest of the `model_fn`. To pass Tensors from the model\n",
        "            to the `metric_fn`, provide as part of the `eval_metrics`. See\n",
        "            https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/TPUEstimatorSpec\n",
        "            for more information.\n",
        "            Arguments should match the list of `Tensor` objects passed as the second\n",
        "            element in the tuple passed to `eval_metrics`.\n",
        "            Args:\n",
        "            labels: `Tensor` with shape `[batch, ]`.\n",
        "            logits: `Tensor` with shape `[batch, num_classes]`.\n",
        "            Returns:\n",
        "            A dict of the metrics to return from evaluation.\n",
        "            \"\"\"\n",
        "            probs=tf.nn.sigmoid(logits)\n",
        "            predictions = tf.math.greater(probs, 0.2)\n",
        "            recall = tf.metrics.recall(labels, predictions)\n",
        "            precision=tf.metrics.precision(labels, predictions)\n",
        "            f1=tf.contrib.metrics.f1_score(labels, probs)\n",
        "\n",
        "            return {\n",
        "              'recall': recall,\n",
        "              'precision': precision,\n",
        "              'f1': f1\n",
        "            }\n",
        "\n",
        "        eval_metrics = (metric_fn, [labels, logits])\n",
        "\n",
        "    return tf.contrib.tpu.TPUEstimatorSpec(\n",
        "        mode=mode,\n",
        "        loss=loss,\n",
        "        train_op=train_op,\n",
        "        host_call=host_call,\n",
        "        eval_metrics=eval_metrics)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4fSZX5_Tv44y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LoadEMAHook(tf.train.SessionRunHook):\n",
        "  \"\"\"Hook to load exponential moving averages into corresponding variables.\"\"\"\n",
        "\n",
        "  def __init__(self, model_dir):\n",
        "    super(LoadEMAHook, self).__init__()\n",
        "    self._model_dir = model_dir\n",
        "\n",
        "  def begin(self):\n",
        "    ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
        "    variables_to_restore = ema.variables_to_restore()\n",
        "    self._load_ema = tf.contrib.framework.assign_from_checkpoint_fn(\n",
        "        tf.train.latest_checkpoint(self._model_dir), variables_to_restore)\n",
        "\n",
        "  def after_create_session(self, sess, coord):\n",
        "    tf.logging.info('Reloading EMA...')\n",
        "    self._load_ema(sess)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "atKLBN6BwJaZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def do_it(mode):\n",
        "  params = {\n",
        "      'input_perm': [0, 1, 2, 3],\n",
        "      'output_perm': [0, 1, 2, 3],\n",
        "      'warmup': mode=='warmup',\n",
        "      'mode': mode,\n",
        "  }\n",
        "\n",
        "  if mode == 'retrain':\n",
        "    # wipe checkpoints\n",
        "    files=tf.gfile.ListDirectory(model_dir)\n",
        "    for f in files:\n",
        "        fname=model_dir+f\n",
        "        fs = tf.gfile.Stat(fname)\n",
        "        if not fs.is_directory:\n",
        "            tf.gfile.Remove(fname)\n",
        "\n",
        "    do_it('warmup')\n",
        "    do_it('train')\n",
        "  if mode == 'warmup':\n",
        "    mode = 'train'\n",
        "  if mode == 'retrain_and_eval':\n",
        "    # wipe checkpoints\n",
        "    files=tf.gfile.ListDirectory(model_dir)\n",
        "    for f in files:\n",
        "        fname=model_dir+f\n",
        "        fs = tf.gfile.Stat(fname)\n",
        "        if not fs.is_directory:\n",
        "            tf.gfile.Remove(fname)\n",
        "    do_it('warmup')\n",
        "    do_it('train_and_eval')\n",
        "\n",
        "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "  tf.logging.info('Precision: %s', precision)\n",
        "\n",
        "  if mode == 'predict':\n",
        "        batch_axis=None\n",
        "  else:\n",
        "    batch_axis = 0\n",
        "    if transpose_enabled:\n",
        "        params['input_perm'] = [3, 0, 1, 2]\n",
        "        params['output_perm'] = [1, 2, 3, 0]\n",
        "        batch_axis = 3\n",
        "    batch_axis=(batch_axis, 0)\n",
        "\n",
        "  eval_size = _NUM_EVAL_IMAGES\n",
        "  eval_steps = eval_size // geval_batch_size\n",
        "\n",
        "  iterations = (eval_steps if mode == 'eval' else save_summary_steps)\n",
        "\n",
        "  eval_batch_size = (None if mode == 'train' else geval_batch_size)\n",
        "\n",
        "  per_host_input_for_training = (num_shards <= 8 if mode == 'train' else True)\n",
        "\n",
        "  run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=model_dir,\n",
        "    save_checkpoints_secs=save_checkpoints_secs,\n",
        "    save_summary_steps=save_summary_steps,\n",
        "    session_config=tf.ConfigProto(\n",
        "        allow_soft_placement=True,\n",
        "        log_device_placement=log_device_placement),\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=iterations,\n",
        "        num_shards=num_shards,\n",
        "        per_host_input_for_training=per_host_input_for_training))\n",
        "\n",
        "  trainable_vars = tf.contrib.framework.get_model_variables()\n",
        "  #print(trainable_vars)\n",
        "  skip_vars=['InceptionV3/AuxLogits/Conv2d_2b_1x1/weights']\n",
        "  load_vars = tf.contrib.framework.filter_variables(trainable_vars, exclude_patterns=skip_vars)\n",
        "  #print(load_vars)\n",
        "  ws = tf.estimator.WarmStartSettings(\n",
        "      ckpt_to_initialize_from=DATA_DIR+\"pre-trained/inception_v3.ckpt\",\n",
        "      vars_to_warm_start=load_vars\n",
        "  )\n",
        "\n",
        "  inception_classifier = tf.contrib.tpu.TPUEstimator(\n",
        "    model_fn=inception_model_fn,\n",
        "    use_tpu=use_tpu,\n",
        "    config=run_config,\n",
        "    warm_start_from=ws,\n",
        "    params=params,\n",
        "    train_batch_size=train_batch_size,\n",
        "    eval_batch_size=eval_batch_size,\n",
        "    predict_batch_size=32,\n",
        "    batch_axis=batch_axis)\n",
        "    \n",
        "\n",
        "  # Input pipelines are slightly different (with regards to shuffling and\n",
        "  # preprocessing) between training and evaluation.\n",
        "  use_bfloat16 = precision == 'bfloat16'\n",
        "  imagenet_train = tg\n",
        "  imagenet_eval = vg\n",
        "\n",
        "  imagenet_predict=test\n",
        "\n",
        "  if moving_average:\n",
        "    eval_hooks = [LoadEMAHook(model_dir)]\n",
        "  else:\n",
        "    eval_hooks = []\n",
        "\n",
        "  if mode == 'eval':\n",
        "    # Run evaluation when there is a new checkpoint\n",
        "    for checkpoint in evaluation.checkpoints_iterator(\n",
        "        model_dir, timeout=eval_timeout):\n",
        "      tf.logging.info('Starting to evaluate.')\n",
        "      try:\n",
        "        start_timestamp = time.time()  # Includes compilation time\n",
        "        eval_results = inception_classifier.evaluate(\n",
        "            input_fn=imagenet_eval.input_fn,\n",
        "            steps=eval_steps,\n",
        "            hooks=eval_hooks,\n",
        "            checkpoint_path=checkpoint)\n",
        "        elapsed_time = int(time.time() - start_timestamp)\n",
        "        tf.logging.info(\n",
        "            'Eval results: %s. Elapsed seconds: %d', eval_results, elapsed_time)\n",
        "\n",
        "        # Terminate eval job when final checkpoint is reached\n",
        "        current_step = int(os.path.basename(checkpoint).split('-')[1])\n",
        "        if current_step >= train_steps:\n",
        "          tf.logging.info(\n",
        "              'Evaluation finished after training step %d', current_step)\n",
        "          break\n",
        "      except tf.errors.NotFoundError:\n",
        "        # Since the coordinator is on a different job than the TPU worker,\n",
        "        # sometimes the TPU worker does not finish initializing until long after\n",
        "        # the CPU job tells it to start evaluating. In this case, the checkpoint\n",
        "        # file could have been deleted already.\n",
        "        tf.logging.info(\n",
        "            'Checkpoint %s no longer exists, skipping checkpoint', checkpoint)\n",
        "\n",
        "  elif mode == 'train_and_eval':\n",
        "    for cycle in range(train_steps // train_steps_per_eval):\n",
        "      tf.logging.info('Starting training cycle %d.' % cycle)\n",
        "      inception_classifier.train(\n",
        "          input_fn=imagenet_train.input_fn, steps=train_steps_per_eval)\n",
        "\n",
        "      tf.logging.info('Starting evaluation cycle %d .' % cycle)\n",
        "      eval_results = inception_classifier.evaluate(\n",
        "          input_fn=imagenet_eval.input_fn, steps=eval_steps, hooks=eval_hooks)\n",
        "      tf.logging.info('Evaluation results: %s' % eval_results)\n",
        "  elif mode == 'predict':\n",
        "    return inception_classifier.predict(input_fn=imagenet_predict.input_fn)\n",
        "  else:\n",
        "    tf.logging.info('Starting training ...')\n",
        "    if params['warmup']:\n",
        "        steps = train_steps_per_eval*2 # ~2 epochs\n",
        "        print('warming up for ', steps)\n",
        "    else:\n",
        "        steps = train_steps\n",
        "        print('training for ')\n",
        "    inception_classifier.train(\n",
        "        input_fn=imagenet_train.input_fn, steps=steps)\n",
        "\n",
        "  #if export_dir is not None:\n",
        "  #  tf.logging.info('Starting to export model.')\n",
        "  #  inception_classifier.export_saved_model(\n",
        "  #      export_dir_base=export_dir,\n",
        "  #      serving_input_receiver_fn=image_serving_input_fn)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RrRGqcnH5Pem",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "#tf.logging.set_verbosity(tf.logging.INFO)\n",
        "#do_it('retrain')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TYN3etXr2NRM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#do_it('eval')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NgCutQhuc1B9",
        "colab_type": "code",
        "outputId": "e32b1473-9e9e-4fe3-d851-d028e54469d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "cell_type": "code",
      "source": [
        "results = do_it('predict')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Precision: float32\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://human-protein-atlas-kaggle/output/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 1000, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      value: \"10.110.132.194:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f54304964a8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': b'grpc://10.110.132.194:8470', '_evaluation_master': b'grpc://10.110.132.194:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.contrib.cluster_resolver.python.training.tpu_cluster_resolver.TPUClusterResolver object at 0x7f54304963c8>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Otg-xagt-ar1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5763
        },
        "outputId": "d7e7870a-866b-462e-a2d5-051797740eb1"
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "with file_io.FileIO(DATA_DIR+'sample_submission.csv', 'r') as f:\n",
        "    submit = pd.read_csv(f)\n",
        "for r in tqdm(results, total=submit.values.shape[0]):\n",
        "    classes=''\n",
        "    for i in range(28):\n",
        "        if r['predictions'][i]>0.2:\n",
        "            classes+=str(i)+' '\n",
        "    if classes == '':\n",
        "        c=np.argmax(r['predictions'])\n",
        "        classes=str(c)\n",
        "    ids='{0:08x}-{1:04x}-{2:04x}-{3:04x}-{4:012x}'.format(*r['ids'])\n",
        "    submit[submit.Id==r['ids'].decode('utf8')].Target=classes\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/11702 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.110.132.194:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 5430434907095332708)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14767560081273852568)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 11834093469595998535)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4328427905541093280)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 17340163491948052446)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4312709332169993133)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 860592450322314050)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 74513726444831943)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 3445617430047872947)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 1856635537024405041)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 8184955560853351095)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 18376990445723569978)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "Tensor(\"arg1:0\", shape=(?,), dtype=string, device=/job:worker/task:0/device:CPU:0)\n",
            "SparseTensor(indices=Tensor(\"StringSplitV2:0\", shape=(?, 2), dtype=int64, device=/job:worker/task:0/device:CPU:0), values=Tensor(\"StringSplitV2:1\", shape=(?,), dtype=string, device=/job:worker/task:0/device:CPU:0), dense_shape=Tensor(\"StringSplitV2:2\", shape=(2,), dtype=int64, device=/job:worker/task:0/device:CPU:0))\n",
            "Tensor(\"SparseToDense:0\", shape=(?, ?), dtype=string, device=/job:worker/task:0/device:CPU:0)\n",
            "Tensor(\"StringToNumber:0\", shape=(?, ?), dtype=int32, device=/job:worker/task:0/device:CPU:0)\n",
            "Tensor(\"Reshape:0\", shape=(?, 5), dtype=int32, device=/job:worker/task:0/device:CPU:0)\n",
            "<PrefetchDataset shapes: ({image: (32, 299, 299, 3), ids: (32, 5)}, (32, 28)), types: ({image: tf.float32, ids: tf.int32}, tf.float32)>\n",
            "{'image': <tf.Tensor 'InfeedQueue/dequeue:1' shape=(4, 299, 299, 3) dtype=float32>, 'ids': <tf.Tensor 'InfeedQueue/dequeue:0' shape=(4, 5) dtype=int32>}\n",
            "Tensor(\"InfeedQueue/dequeue:2\", shape=(4, 28), dtype=float32, device=/device:TPU_REPLICATED_CORE:0)\n",
            "infer\n",
            "{'input_perm': [0, 1, 2, 3], 'output_perm': [0, 1, 2, 3], 'warmup': False, 'mode': 'predict', 'batch_size': 4, 'use_tpu': True, 'context': <tensorflow.contrib.tpu.python.tpu.tpu_context.TPUContext object at 0x7f543f28c780>}\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "Tensor(\"InceptionV3/Logits/Dropout_1b/dropout/mul:0\", shape=(4, 256), dtype=float32)\n",
            "Tensor(\"InceptionV3/Logits/ExpandDims_1:0\", shape=(4, 1, 1, 256), dtype=float32)\n",
            "{'logits': <tf.Tensor 'InceptionV3/Logits/SpatialSqueeze:0' shape=(4, 28) dtype=float32>, 'classes': <tf.Tensor 'Greater:0' shape=(4, 28) dtype=bool>, 'probabilities': <tf.Tensor 'InceptionV3/Logits/Predictions:0' shape=(4, 28) dtype=float32>, 'predictions': <tf.Tensor 'InceptionV3/Logits/Predictions:0' shape=(4, 28) dtype=float32>, 'ids': <tf.Tensor 'InfeedQueue/dequeue:0' shape=(4, 5) dtype=int32>}\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://human-protein-atlas-kaggle/output/model.ckpt-3008\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 7 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:An error was raised. This may be due to a preemption in a connected worker or parameter server. The current session will be closed and a new session will be created. This error may also occur due to a gRPC failure caused by high memory or network bandwidth usage in the parameter servers. If this error occurs repeatedly, try increasing the number of parameter servers assigned to the job. Error: Socket closed\n",
            "INFO:tensorflow:Error recorded from infeed: Socket closed\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://human-protein-atlas-kaggle/output/model.ckpt-3008\n",
            "INFO:tensorflow:Error recorded from prediction_loop: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n",
            "\n",
            "Unsuccessful TensorSliceReader constructor: Failed to get matching files on gs://human-protein-atlas-kaggle/output/model.ckpt-3008: Permission denied: Error executing an HTTP request: HTTP response code 403 with body '{\n",
            " \"error\": {\n",
            "  \"errors\": [\n",
            "   {\n",
            "    \"domain\": \"global\",\n",
            "    \"reason\": \"forbidden\",\n",
            "    \"message\": \"service-495559152420@cloud-tpu.iam.gserviceaccount.com does not have storage.objects.list access to human-protein-atlas-kaggle.\"\n",
            "   }\n",
            "  ],\n",
            "  \"code\": 403,\n",
            "  \"message\": \"service-495559152420@cloud-tpu.iam.gserviceaccount.com does not have storage.objects.list access to human-protein-atlas-kaggle.\"\n",
            " }\n",
            "}\n",
            "'\n",
            "\t when reading gs://human-protein-atlas-kaggle/output\n",
            "\t [[node save/RestoreV2 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py:2440)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:worker/replica:0/task:0/device:CPU:0\"](_recv_save/Const_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
            "\n",
            "Caused by op 'save/RestoreV2', defined at:\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n",
            "    ioloop.IOLoop.instance().start()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 832, in start\n",
            "    self._run_callback(self._callbacks.popleft())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 605, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n",
            "    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
            "    self._handle_recv()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
            "    self._run_callback(callback, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
            "    user_expressions, allow_stdin)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-60-84e47ac29efc>\", line 5, in <module>\n",
            "    for r in tqdm(results, total=submit.values.shape[0]):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 979, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2440, in predict\n",
            "    yield_single_examples=yield_single_examples):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 593, in predict\n",
            "    hooks=all_hooks) as mon_sess:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 921, in __init__\n",
            "    stop_grace_period_secs=stop_grace_period_secs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 643, in __init__\n",
            "    self._sess = _RecoverableSession(self._coordinated_creator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1107, in __init__\n",
            "    _WrappedSession.__init__(self, self._create_session())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1112, in _create_session\n",
            "    return self._sess_creator.create_session()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 800, in create_session\n",
            "    self.tf_sess = self._session_creator.create_session()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 557, in create_session\n",
            "    self._scaffold.finalize()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 213, in finalize\n",
            "    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 886, in _get_saver_or_default\n",
            "    saver = Saver(sharded=True, allow_empty=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1102, in __init__\n",
            "    self.build()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1114, in build\n",
            "    self._build(self._filename, build_save=True, build_restore=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1151, in _build\n",
            "    build_save=build_save, build_restore=build_restore)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 789, in _build_internal\n",
            "    restore_sequentially, reshape)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 459, in _AddShardedRestoreOps\n",
            "    name=\"restore_shard\"))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 406, in _AddRestoreOps\n",
            "    restore_sequentially)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 862, in bulk_restore\n",
            "    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1466, in restore_v2\n",
            "    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n",
            "    op_def=op_def)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n",
            "InvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n",
            "\n",
            "Unsuccessful TensorSliceReader constructor: Failed to get matching files on gs://human-protein-atlas-kaggle/output/model.ckpt-3008: Permission denied: Error executing an HTTP request: HTTP response code 403 with body '{\n",
            " \"error\": {\n",
            "  \"errors\": [\n",
            "   {\n",
            "    \"domain\": \"global\",\n",
            "    \"reason\": \"forbidden\",\n",
            "    \"message\": \"service-495559152420@cloud-tpu.iam.gserviceaccount.com does not have storage.objects.list access to human-protein-atlas-kaggle.\"\n",
            "   }\n",
            "  ],\n",
            "  \"code\": 403,\n",
            "  \"message\": \"service-495559152420@cloud-tpu.iam.gserviceaccount.com does not have storage.objects.list access to human-protein-atlas-kaggle.\"\n",
            " }\n",
            "}\n",
            "'\n",
            "\t when reading gs://human-protein-atlas-kaggle/output\n",
            "\t [[node save/RestoreV2 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py:2440)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:worker/replica:0/task:0/device:CPU:0\"](_recv_save/Const_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
            "\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "WARNING:tensorflow:Reraising captured error\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnavailableError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnavailableError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnavailableError\u001b[0m: Socket closed",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mUnavailableError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-84e47ac29efc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'sample_submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msubmit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m   2444\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction_loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m     \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction_loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/error_handling.py\u001b[0m in \u001b[0;36mraise_errors\u001b[0;34m(self, timeout_sec)\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reraising captured error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkept_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/error_handling.py\u001b[0m in \u001b[0;36mcatch_errors\u001b[0;34m(self, source, session)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m\"\"\"Context manager to report any errors within a block.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36m_run_infeed\u001b[0;34m(self, queue_ctx, session)\u001b[0m\n\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueue_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_iteration_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m           \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enqueue_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Infeed thread finished, shutting down.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnavailableError\u001b[0m: Socket closed"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "QyG3EzUojv-g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submit.to_csv('inception_rnn.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HwJ8fqDWdopP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}